#!/home/jack/Desktop/StoryMaker/env/bin/python
from flask import Flask, render_template, request, redirect, url_for, send_from_directory, Response,flash
from flask import send_file
import os
import pygame
from gtts import gTTS
import cv2
import dlib
import numpy as np
from random import randint
from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip
from moviepy.editor import concatenate_videoclips, AudioFileClip, TextClip
import moviepy.editor
import subprocess 
import shutil  
import logging
import random
import glob
import base64
import datetime
import imageio
import time
from werkzeug.utils import secure_filename
import shutil
import logging
import search
import clean_images
from time import sleep
from pydub import AudioSegment
from PIL import Image
from logging.handlers import RotatingFileHandler
app = Flask(__name__)
app.secret_key = os.urandom(24)

# Create a logger object
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# Create a formatter for the log messages
formatter = logging.Formatter('%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]')

# Create a file handler to write log messages to a file
file_handler = RotatingFileHandler('Logs/app.log', maxBytes=10000, backupCount=1)
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(formatter)

# Add the file handler to the logger
logger.addHandler(file_handler)

# Now you can use the logger to log messages
TExt = "TEXT TEST 12345"
logger.debug('This is a debug message: %s', TExt)
TExt = "TEXT TEST 6789"
logger.debug('This is a debug message: %s', TExt)
TExt = "TEXT TEST abcd"
logger.debug('This is a debug message: %s', TExt)
# Set up logging for the Flask app
app.logger.addHandler(file_handler)
# Create a logger object
logging.basicConfig(level=logging.DEBUG)

app.config['UPLOAD_FOLDER'] = 'static/images/uploads'
app.config['RESULTS_FOLDER'] = 'static/videos/results'
app.config['THUMBNAILS_FOLDER'] = 'static/images/thumbnails'
app.config['CHECKPOINT_PATH'] = 'checkpoints/wav2lip_gan.pth'
app.config['AUDIO_PATH'] = 'sample_data/input_audio.wav'
app.config['video_PATH'] = 'sample_data/input_videio.mp4'


# use the search function as a route
app.add_url_rule('/search', 'search', search)

def zip_lists(list1, list2):
    return zip(list1, list2)

app.jinja_env.filters['zip'] = zip_lists

directory_path = 'temp'  # Replace with the desired directory path
# Create the directory if it doesn't exist
os.makedirs(directory_path, exist_ok=True)

@app.route('/')
def index():
    image_dir = 'static/images'
    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]
    random_image_file = random.choice(image_files)
    return render_template('index.html', random_image_file="images/"+random_image_file)

def generate_output():
    # Specify the path to your Bash script
    bash_script_path = '/home/jack/Desktop/content/MakeVideo'

    # Execute the Bash script
    subprocess.run(['bash', bash_script_path])
    # Backup the result_videoxx.mp4 file
    current_datetime = str(int(time.time())) 
    backup_filename = f"static/{current_datetime}.mp4"
    shutil.copyfile("results/result_voice.mp4", backup_filename)    
    redirect('/final_lipsync')
    return "Generated output"


@app.route('/create_avatar', methods=['GET', 'POST'])
def create_avatar():
      if request.method == 'POST':
          #check_point = os.path.join(app.config['CHECKPOINT_PATH'], 'checkpoints/wav2lip_gan.pth')

          return Response(generate_output(), mimetype='text/plain')
      else:
          return render_template('create_avatar.html')
  

@app.route('/run_command', methods=['GET'])
def run_command():
    # Specify the path to your Bash script
    bash_script_path = '/home/jack/Desktop/content/MakeVideo'

    # Execute the Bash script
    subprocess.run(['bash', bash_script_path])
    # Backup the result_videoxx.mp4 file
    current_datetime = str(int(time.time())) 
    backup_filename = f"static/{current_datetime}.mp4"
    shutil.copyfile("results/result_voice.mp4", backup_filename)    
    redirect('/final_lipsync')

@app.route('/result/<filename>')
def result(filename):
    return render_template('result.html', filename=filename)
  
@app.route('/convert_mp3_to_wav', methods=['GET', 'POST'])
def convert_mp3_to_wav():
    if request.method == 'POST':
        mp3_file = request.files['mp3_file']
        mp3_filename = mp3_file.filename
        mp3_path = os.path.join(app.static_folder, 'audio_mp3', mp3_filename)
        mp3_file.save(mp3_path)

        wav_filename = 'input_audio.wav'
        wav_path = os.path.join('sample_data', wav_filename)

        sound = AudioSegment.from_mp3(mp3_path)
        sound.export(wav_path, format='wav')

        return 'MP3 file converted to WAV successfully'
    else:
        return render_template('convert_mp3_to_wav.html')
 
 
@app.route('/final_lipsync')
def final_lipsync():
    VIDEO = 'result/result_voice.mp4'
    return render_template('final_lipsync.html', video=VIDEO)
   
@app.route('/text_mp3', methods=['GET', 'POST'])
def text_mp3():
    if request.method == 'POST':
        # Get the text from the textarea
        text = request.form['text']
        text0 = text
        # Remove whitespace from the text
        text = text.replace(" ", "")
        # Create a filename based on the first 25 characters of the text
        filename = "static/audio_mp3/" + text[:25] + ".mp3"
        textname = text[:25] + ".txt"
        # Save the text to a text file
        textname = textname.strip()
        with open("static/text/"+textname, 'w') as f:
            f.write(text0)
        filename = filename.strip()  # remove the newline character
        # Create a gTTS object and save the audio file
        tts = gTTS(text)
        filename = filename.strip() 
        tts.save(filename)
        shutil.copy(filename, 'static/TEMP.mp3')
        # Play the mp3 file
        pygame.mixer.init()
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        # Wait for the audio to finish playing
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
        # Stop pygame and exit the program
        pygame.mixer.quit()
        pygame.quit()
        # Return the text and filename to the template
        return render_template('text_mp3.html', text=text, filename=filename)
    else:
        # Render the home page template
        return render_template('text_mp3.html')
@app.route('/mp3_upload', methods=['POST'])
def mp3_upload():
    if 'file' not in request.files:
        return 'No file uploaded', 400

    file = request.files['file']
    if file.filename == '':
        return 'No file selected', 400

    if file:
        audio_file = 'static/TEMP.mp3'
        file.save(audio_file)
        return render_template('player.html', audio_file=audio_file)
    
@app.route('/generate_video', methods=['GET', 'POST'])
def generate_video():
    if request.method == 'POST':
        # Set the input and output filenames
        eyes_filename = 'static/TEMP.png'
        input_filename = 'static/TEMP2.mp4'
        output_filename = 'static/TEMP2.mp4'
        
        # Set the paths for the video and audio files
        audio_file = 'static/TEMP.mp3'
        output_filenames = 'static/TEMP.mp4'
        
        # Extract eyes from the uploaded image and save as eyes_test.png
        image_path = "static/TEMP.jpg"
        shape_predictor_path = "/home/jack/hidden/shape_predictor_68_face_landmarks.dat"
        extract_eyes(image_path, eyes_filename, shape_predictor_path)
        
        # Load the image clip
        image_clip = ImageClip(image_path, duration=30)
        
        # Set the final clip properties
        final_clip = image_clip.set_audio(None)
        final_clip = final_clip.set_position('center')
        
        # Write the final video
        final_clip.write_videofile(output_filename, codec='libx264', fps=30, audio=False)
        
        # Load the input video without audio
        input_clip = VideoFileClip(input_filename, audio=False)
        
        # Load the eye image clip
        eyes_clip = ImageClip(eyes_filename)
        
        # Create multiple looping clips
        clips = []
        for i in range(8):
            loop_clip = mkloop(input_clip, eyes_clip)
            clips.append(loop_clip)
        
        # Concatenate all the clips
        final_clips = concatenate_videoclips(clips)
        
        # Write the final video
        final_clips.write_videofile(output_filenames, codec='libx264', fps=input_clip.fps, audio=False)
        
        # Load the video and audio files
        video_clip = VideoFileClip(output_filenames)
        audio_clip = AudioFileClip(audio_file)
        
        # Set the duration of the final video to match the audio clip's duration
        final_duration = audio_clip.duration+.5
        
        # Set the video clip's duration to match the final duration
        video_clip = video_clip.set_duration(final_duration)
        
        # Set the audio of the video clip to be the same as the loaded audio clip
        video_clip = video_clip.set_audio(audio_clip)
        
        # Write the final video file
        output_path = "static/final_video.mp4"
        video_clip.write_videofile(output_path, codec='libx264', audio_codec='aac', fps=24)
        
        return render_template('generate_video.html', video_path=output_path)
    
    return render_template('generate_video.html')

# Function to extract eyes from an image using dlib
def extract_eyes(image_path, eyes_filename, shape_predictor_path):
    # Load the image and shape predictor model
    image = cv2.imread(image_path)
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor(shape_predictor_path)

    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Detect faces in the image
    faces = detector(gray)

    # Iterate over the detected faces and extract the eye regions
    for face in faces:
        landmarks = predictor(gray, face)

        # Extract the coordinates of the left eye
        left_eye_pts = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]

        # Extract the coordinates of the right eye
        right_eye_pts = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]

        # Create a transparent image with an alpha channel
        transparent_image = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)

        # Define the skin color (e.g., light brown or tan) in BGR format
        skin_color_bgr = (210, 180, 140)

        # Convert BGR to RGB
        skin_color_rgb = (skin_color_bgr[2], skin_color_bgr[1], skin_color_bgr[0])

        # Draw the eye regions on the transparent image with the skin color and alpha channel
        cv2.fillPoly(transparent_image, [np.array(left_eye_pts)], skin_color_rgb + (200,))
        cv2.fillPoly(transparent_image, [np.array(right_eye_pts)], skin_color_rgb + (200,))
        blurred_image = cv2.GaussianBlur(transparent_image, (5, 5), 0)
        # Save the transparent image with only the eyes as a PNG file
        cv2.imwrite(eyes_filename, blurred_image)


# Function to create a looping clip with blinking eyes
def mkloop(input_clip, eyes_clip):
    # Set the duration of the eye image clip
    eyes_duration = 0.1  # seconds

    # Set the position of the eye image clip
    eyes_position = 'center'

    # Set the start time of the eye image clip
    blink_start_time = randint(2, 4)

    # Create a CompositeVideoClip with the input video and the eye image clip
    final_clip = CompositeVideoClip([input_clip, eyes_clip.set_duration(eyes_duration)
                                                      .set_position(eyes_position)
                                                      .set_start(blink_start_time)])

    # Calculate the duration of the final clip
    final_duration = blink_start_time + eyes_duration + randint(2, 4)  # 5 to 8 seconds after the blink

    # Set the duration of the final clip
    final_clip = final_clip.set_duration(final_duration)
    return final_clip

def apply_text(mp4_path, text, x, y):
    video = moviepy.editor.VideoFileClip(mp4_path)
    font = "/home/jack/fonts/OpenSansBold.ttf"
    text_clip = moviepy.editor.TextClip(text, font=font, fontsize=24, color="white")

    try:
        x = int(x)
        y = int(y)
    except ValueError:
        raise ValueError("Invalid position values. Please provide integer values for x and y.")

    if not (0 <= x <= video.w):
        raise ValueError("Invalid x position. Must be within the width of the video.")
    
    if not (0 <= y <= video.h):
        raise ValueError("Invalid y position. Must be within the height of the video.")

    text_clip = text_clip.set_position((x, y))

    # Check if duration is None and set a default value if necessary
    video_duration = video.duration if video.duration is not None else 0
    text_clip_duration = text_clip.duration if text_clip.duration is not None else 0

    # Set the duration of the video and text clips
    duration = max(video_duration, text_clip_duration)
    video = video.set_duration(duration)
    text_clip = text_clip.set_duration(duration)

    # Create the composite video by overlaying the text clip onto the video clip
    new_video = moviepy.editor.CompositeVideoClip([video, text_clip])

    # Save the new video with the applied text
    new_mp4_path = 'static/TTMP.mp4'
    new_video.write_videofile(new_mp4_path, codec='libx264', audio_codec='aac', remove_temp=False)

    return new_mp4_path




@app.route("/apply_text_to_video", methods=["POST", "GET"])
def apply_text_to_video():
    if request.method == "POST":
        file = request.files["mp4_file"]
        if file.filename == '':
            return redirect(request.url)
        file.save('static/TTMP.mp4')

        mp4_path = 'static/TTMP.mp4'
        text = request.form["text"]
        x = request.form["x"]
        y = request.form["y"]
        new_mp4_path = apply_text(mp4_path, text, x, y)
        return render_template("apply_text_to_video.html", new_mp4_path=new_mp4_path)
    else:
        return render_template("apply_text_to_video.html")

# Get a list of existing subdirectories in the video resources directory
existing_subdirectories = [subdir for subdir in os.listdir("static/current_project") if os.path.isdir(os.path.join("static/current_project", subdir))]

@app.route('/uploads', methods=['GET', 'POST'])
def upload_files():
    video_resources_dir="static/current_project"
    if request.method == 'POST':
        # Get the selected subdirectory from the form
        selected_subdirectory = request.form.get('subdirectory')

        # Check if the selected subdirectory exists
        if selected_subdirectory in existing_subdirectories:
            # Handle the uploaded file
            file = request.files['file']
            if file:
                # Save the file to the selected subdirectory
                file.save(os.path.join(video_resources_dir, selected_subdirectory, file.filename))
                # Get the URL for the uploaded image
                image_path = url_for('static', filename=os.path.join('current_project', selected_subdirectory, file.filename))
                return render_template('upload_files.html', image_path=image_path)
            else:
                return 'No file selected.'
        else:
            return 'Invalid subdirectory selected.'
    # Render the upload form with the list of existing subdirectories
    return render_template('upload_files.html', subdirectories=existing_subdirectories)

@app.route('/get_files', methods=['POST'])
def get_files():
    subdirectory = request.form.get('subdirectory')
    file_options = []
    if subdirectory and subdirectory in existing_subdirectories:
        subdirectory_path = os.path.join("static/current_project", subdirectory)
        files = os.listdir(subdirectory_path)
        file_options = [
            f'<option value="{file}">{file}</option>'
            for file in files
            if os.path.isfile(os.path.join(subdirectory_path, file))
        ]
    return ''.join(file_options)

@app.route('/image_list')
def image_list():
    image_directory = 'static/current_project/Narrators'
    image_list = [
        filename
        for filename in os.listdir(image_directory)
        if filename.endswith('.jpg')
    ]
    return render_template('image_list.html', image_list=image_list)

@app.route('/upload', methods=['POST','GET'])
def upload():
    filename = request.form['filename']
    if filename:
        src_path = 'static/current_project/Narrators/' + filename
        dest_path = 'static/TEMP.jpg'
        shutil.copyfile(src_path, dest_path)
        return redirect('/')
    else:
        return 'No file selected.'


@app.route("/mkblend_videos")
def mkblend_videos():
    # Directory for image files
    DIR = "static/current_project/junk/"
    filelist = glob.glob('animate/*.jpg')  # Get a list of all *.jpg files in the animate/ directory

    for file_path in filelist:
        os.remove(file_path)  # Delete each fil
    # Get a list of image files
    image_list = glob.glob(DIR + "*.jpg")
    
    # Shuffle and select a subset of images
    random.shuffle(image_list)
    image_list = random.sample(image_list, 40)
    
    # Print the number of selected images
    print(len(image_list))
    
    def changeImageSize(maxWidth, maxHeight, image):
        widthRatio = maxWidth / image.size[0]
        heightRatio = maxHeight / image.size[1]
        newWidth = int(widthRatio * image.size[0])
        newHeight = int(heightRatio * image.size[1])
        newImage = image.resize((newWidth, newHeight))
        return newImage
    
    # Get the size of the first image
    imagesize = Image.open(image_list[0]).size
    
    for i in range(len(image_list) - 1):
        imag1 = image_list[i]
        imag2 = image_list[i + 1]
        image1 = Image.open(imag1)
        image2 = Image.open(imag2)

        image3 = changeImageSize(imagesize[0], imagesize[1], image1)
        image4 = changeImageSize(imagesize[0], imagesize[1], image2)

        image5 = image3.convert("RGBA")
        image6 = image4.convert("RGBA")
        
        text = "animate/"
        for ic in range(0,125):
           inc = ic*.008
           sleep(.1)
           #gradually increase opacity
           alphaBlended = Image.blend(image5, image6, alpha=inc)
           alphaBlended = alphaBlended.convert("RGB")
           current_datetime = str(int(time.time())) 
           filename = current_datetime[:-3] + '.jpg'
           alphaBlended.save(f'{text}{filename}')
           if ic %25 ==0:print(i,":",ic, end = " . ")

    from moviepy.video.io.ImageSequenceClip import ImageSequenceClip
    # Get the list of files sorted by creation time
    imagelist = sorted(glob.glob('animate/*.jpg'), key=os.path.getmtime)

    # Create a clip from the images
    clip = ImageSequenceClip(imagelist, fps=30)

    # Write the clip to a video file using ffmpeg
    current_datetime = str(int(time.time())) 
    filename = "static/animate/TEMP3a.mp4"
    clip.write_videofile(filename, fps=24, codec='libx265', preset='medium')
    store = "animate/"+current_datetime[:-3] + 'june25.mp4'
    output_file = "static/animate/TEMP5.mp4"  # Replace with the desired path for the converted video file
    webm_file = "static/animate/TEMP5.webm"  # Replace with the desired path for the converted video file
    ffmpeg_cmd = ['ffmpeg', '-i', filename, '-c:v', 'libx264', '-crf', '23', '-preset', 'medium', '-c:a', 'aac', '-b:a', '128k', '-movflags', '+faststart','-y', output_file]
    subprocess.run(ffmpeg_cmd) 
    ffmpeg_cmd2 = ['ffmpeg', '-i', filename, '-c:v', 'libx264', '-crf', '23', '-preset', 'medium', '-c:a', 'aac', '-b:a', '128k', '-movflags', '+faststart', '-y', webm_file]
    subprocess.run(ffmpeg_cmd2)   
    shutil.copy(filename, store)
    return render_template('mkblend_videos.html', video=filename)

@app.route('/generate_vid', methods=['GET', 'POST'])
def generate_vid():
    current_datetime = str(int(time.time())) 
    str_current_datetime = str(current_datetime)
    logger.debug('Generating video', str_current_datetime)
    if request.method == 'POST':
        # Load the audio file
        audio_file = request.files['audio']
        filename = os.path.join(app.config['AUDIO_PATH'])#, 'input_audio.mp3')
        logger.info(f'Audio path: {filename}')
        audio_file.save(filename)

        # Get the duration of the audio using ffprobe
        command = f"ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 {filename}"
        duration = subprocess.check_output(command.split())
        duration = float(duration.strip().decode())
        logger.info(f'Duration: {duration}')
        # Load the image file
        image_file = request.files['image']
        image_path = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(image_file.filename))
        logger.info(f'Image path: {image_path}')
        image_file.save(image_path)

        # Create the video
        #video_path = os.path.join(app.config['VIDEO_PATH'])#, 'sample_data/input_video.mp4')
        video_path = 'sample_data/input_video.mp4'
        logger.info(f'Video path: {video_path}')
        ffmpeg_command = f"ffmpeg -loop 1 -i {image_path} -c:v libx264 -t {duration+ 0.5} -pix_fmt yuv420p -y {video_path}"
        subprocess.run(ffmpeg_command, shell=True)

        return f'Video created: {video_path}'

    return render_template('generate_vid.html')

# Define route to display upload form
@app.route('/upload_file', methods=['POST', 'GET'])
def upload_file():
    if request.method == 'POST':
        # Check if file was uploaded
        if 'file' not in request.files:
            app.logger.error('No file was uploaded')
            flash('Error: No file was uploaded')
            return redirect(request.url)

        app.logger.error('request.files[\'file\']')
        file = request.files['file']

        # Check if file was selected
        if file.filename == '':
            app.logger.error('No file was selected')
            flash('Error: No file was selected')
            return redirect(request.url)

        # Define allowed file extensions
        ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}

        # Define function to check file extension
        def allowed_file(filename):
            return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

        # Check if file is allowed
        if not allowed_file(file.filename):
             #app.logger.error(f"File '{file.filename}' is not allowed")
             app.logger.error("File '" + file.filename + "' is not allowed")
             flash("Error: File '" + file.filename + "'close is not allowed")
             return redirect(request.url)

        # Save the file
        try:
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
            app.logger.info(f'File {filename} saved')
            app.logger.info('FILENAME:',os.path.join(app.config['UPLOAD_FOLDER'], filename))
        except Exception as e:
            app.logger.error(f'Error saving file: {e}')
            flash('Error: Unable to save file')
            return redirect(request.url)

        # Redirect to the result page
        app.logger.info(f'File-Result {filename} SAVED')
        return redirect(url_for('result', filename=filename))

    # Return the upload form for GET requests
    return render_template('upload_file.html')

@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/make_text', methods=['GET', 'POST'])
def make_text():
    DIR = 'static/text/'
    if request.method == 'POST':
        # Get the text entered in the textarea
        text = request.form.get('text')

        # Generate a filename using the first 25 letters of the text
        text = text.replace(' ', '_')
        filename = text[:25]

        # Save the text to a file
        with open(f'{DIR}{filename}.txt', 'w') as file:
            file.write(text)

        return 'Text saved successfully!'
    else:
        return render_template('make_text.html')
directories = ['static/images','static/images/squares', 'static/final_videos', 'static/Dreamlike_art', 'static/squares', 'static/images/uploads', 'static/BrightColors', 'static/final_images', 'static/thumbnails']
# Route for the home page
@app.route('/')
def home():
    return render_template('choose_dir.html', directories=directories)

# Route for choosing a directory
@app.route('/choose_dir', methods=['GET', 'POST'])
def choose_dir():
    if request.method == 'POST':
        selected_directory = request.form.get('directory', directories)
        TExt = "TEXT TEST"
        logger.error('No file was selected: %s', TExt)
        logger.debug('Debug was selected: %s', TExt)
        if selected_directory is None:
            # Handle the case where no directory is selected
            logger.error('No directory selected')
            return 'No directory selected!'
        # Rest of the code...
        # Use the selected_directory variable in your logic to generate the video
        # Make sure to update the paths according to the selected directory
        logger.debug('Selected directory: %s', selected_directory)
        # Get the list of image files in the selected directory
        image_filenames = random.sample(glob.glob(selected_directory + '/*.jpg'), 10)
        logger.debug('Selected image filenames: %s', image_filenames)
        
        image_clips = []
        for filename in image_filenames:
            # Open the image file and resize it to 512x768
            logger.debug('Processing image: %s', filename)
            image = Image.open(filename)
            #image = image.resize((512, 768), Image.ANTIALIAS)
            # Convert the PIL Image object to a NumPy array
            image_array = np.array(image)
            # Create an ImageClip object from the resized image and set its duration to 1 second
            image_clip = ImageClip(image_array).set_duration(1)
            # Append the image clip to the list
            image_clips.append(image_clip)

        logger.debug('Number of image clips: %d', len(image_clips))

        # Concatenate all the image clips into a single video clip
        video_clip = concatenate_videoclips(image_clips, method='compose')
        timestr = time.strftime("%Y%m%d-%H%M%S")
        # Set the fps value for the video clip
        video_clip.fps = 24
        # Write the video clip to a file
        video_file = f'static/videos/random_images_{timestr}_video.mp4'
        output_p = 'static/videos/random_images_video.mp4'
        logger.debug('Output video file path: %s', video_file)
        logger.debug('Final video file path: %s', output_p)
        
        video_clip.write_videofile(video_file, fps=24)
        
        try:
            shutil.copy(video_file, output_p)
        except Exception as e:
            logger.error('Error occurred while copying file: %s', str(e))
            return f"Error occurred while copying file: {str(e)}"

        # Return the rendered template with the list of directories and output path
        return render_template('choose_dir.html', directories=directories, output_path=output_p)

    # If the request method is GET, render the form template with the list of directories
    output_p = 'static/videos/random_images_video.mp4'
    return render_template('choose_dir.html', directories=directories, output_path=output_p)


  
@app.route('/convert', methods=['GET', 'POST'])
def convert():
    if request.method == 'POST':
        try:
            audio_file = request.files['audio_file']
            audio_file_path = f'static/audio_mp3/{audio_file.filename}'  # Path for audio file
            audio_file.save(audio_file_path)  # Save the audio file to the specified location

            formatted_text_file = request.files['formatted_text_file']
            formatted_text_file_path = f'static/formatted_text/{formatted_text_file.filename}'  # Path for formatted text file
            formatted_text_file.save(formatted_text_file_path)  # Save the formatted text file to the specified location

            output_filename = datetime.datetime.now().strftime('%Y-%m-%d') + '.mp4'
            output_path = 'static/videos/' + output_filename

            command = [
    'ffmpeg',
    '-i', audio_file_path,
    '-f', 'lavfi',
    '-i', f"color='#470000'@0.0:s=1280x720:rate=60,format=rgba",
    '-vf', f"drawtext=textfile='{os.path.abspath(formatted_text_file_path)}':y=(h-120)-12*t:x=480:fontcolor=orange:fontfile=/home/jack/Arimo-Regular.ttf:fontsize=26",
    '-t', '280',
    '-y', output_path
]

            logger.debug(f"Command: {' '.join(command)}")

            subprocess.run([str(arg) for arg in command], check=True)
            video = f'{output_filename}'
            return render_template('convert.html', video=output_path)
        except Exception as e:
            logger.exception("An error occurred during video conversion:")
            return render_template('error.html', message="An error occurred during video conversion.")
    else:
        return render_template('convert_form.html')

  
  

@app.route('/mk_text', methods=['GET', 'POST'])
def mk_text():
    DIR = "static/text/"
    if request.method == 'POST':
        text = request.form.get('text')
        tex = text.replace(" ", "_")
        filename = tex[:25]
        with open(f'{DIR}{filename}.txt', 'w') as file:
            file.write(text)
        return render_template('mk_text.html', text=text, filename=f'{filename}.txt')
    else:
        return render_template('mk_text.html')

@app.route('/list_files')
def list_files():
    static_text_dir = 'static/text/'
    files = os.listdir(static_text_dir)
    files = [file for file in files if os.path.isfile(os.path.join(static_text_dir, file))]
    return str(files)

@app.route('/format_file', methods=['POST', 'GET'])
def format_file():
    static_text_dir = 'static/text/'
    static_format_dir = 'static/formatted_text/'    
    if request.method == 'POST':
        filename = request.form.get('filename')
        file_path = os.path.join(static_text_dir, filename)
        if not os.path.isfile(file_path):
            return render_template('error.html', message=f'File "{filename}" does not exist')
        with open(file_path, 'r') as file:
            content = file.read()
        words = content.split()
        formatted_content = '\n'.join([' '.join(words[i:i+5]) for i in range(0, len(words), 5)])
        modified_filename = filename.replace('.txt', '') + 'FORMATTED.txt'
        modified_file_path = os.path.join(static_format_dir, modified_filename)
        with open(modified_file_path, 'w') as modified_file:
            modified_file.write(formatted_content)
            logger.debug('This is Formated Content: %s', formatted_content)
            logger.debug('This is Formated file: %s', modified_file_path)
        return render_template('success.html', original_file=filename, modified_file=modified_filename)
    
    file_options = []
    for file_name in os.listdir(static_text_dir):
        if file_name.endswith('.txt'):
            file_options.append(file_name)
    
    return render_template('form.html', file_options=file_options)

@app.route('/view_text')
def view_text():
    text_files_dir = 'static/text/'
    text_files = []
    for filename in os.listdir(text_files_dir):
        if filename.endswith('.txt'):
            text_files.append(filename)
    return render_template('select_file.html', text_files=text_files)

@app.route('/view_text/<filename>')
def display_text(filename):
    text_file_path = f'static/text/{filename}'
    try:
        with open(text_file_path, 'r') as file:
            file_contents = file.read()
        return render_template('view_text.html', file_contents=file_contents, filename=filename)
    except FileNotFoundError:
        return f'Text file {filename} not found.'

@app.route('/edit_file', methods=['GET', 'POST'])
def edit_file():
    if request.method == 'POST':
        filename = request.form.get('filename')
        text = request.form.get('text')
        with open(f'static/text/{filename}', 'w') as file:
            file.write(text)
    text_files_dir = 'static/text/'
    text_files = []
    for filename in os.listdir(text_files_dir):
        if filename.endswith('.txt'):
            text_files.append(filename)
    return render_template('edit_file.html', text_files=text_files)
@app.route('/get_file_content/<filename>')
def get_file_content(filename):
    file_path = os.path.join('static/text', filename)
    with open(file_path, 'r') as file:
        content = file.read()
    return content

@app.route("/mkblend_video")
def mkblend_video():
    # Directory for image files
    DIR = "static/current_project/quantum/"
    filelist = glob.glob('animate/*.jpg')  # Get a list of all *.jpg files in the animate/ directory

    for file_path in filelist:
        os.remove(file_path)  # Delete each fil
    # Get a list of image files
    image_list = glob.glob(DIR + "*.jpg")
    
    # Shuffle and select a subset of images
    random.shuffle(image_list)
    image_list = random.sample(image_list, 60)
    
    # Print the number of selected images
    print(len(image_list))
    
    def changeImageSize(maxWidth, maxHeight, image):
        widthRatio = maxWidth / image.size[0]
        heightRatio = maxHeight / image.size[1]
        newWidth = int(widthRatio * image.size[0])
        newHeight = int(heightRatio * image.size[1])
        newImage = image.resize((newWidth, newHeight))
        return newImage
    
    # Get the size of the first image
    imagesize = Image.open(image_list[0]).size
    
    for i in range(len(image_list) - 1):
        imag1 = image_list[i]
        imag2 = image_list[i + 1]
        image1 = Image.open(imag1)
        image2 = Image.open(imag2)

        image3 = changeImageSize(imagesize[0], imagesize[1], image1)
        image4 = changeImageSize(imagesize[0], imagesize[1], image2)

        image5 = image3.convert("RGBA")
        image6 = image4.convert("RGBA")
        
        text = "animate/"
        for ic in range(0,125):
           inc = ic*.008
           sleep(.1)
           #gradually increase opacity
           alphaBlended = Image.blend(image5, image6, alpha=inc)
           alphaBlended = alphaBlended.convert("RGB")
           current_time = datetime.datetime.now()
           filename = current_time.strftime('%Y%m%d_%H%M%S%f')[:-3] + '.jpg'
           alphaBlended.save(f'{text}{filename}')
           if ic %25 ==0:print(i,":",ic, end = " . ")

    from moviepy.video.io.ImageSequenceClip import ImageSequenceClip
    # Get the list of files sorted by creation time
    imagelist = sorted(glob.glob('animate/*.jpg'), key=os.path.getmtime)

    # Create a clip from the images
    clip = ImageSequenceClip(imagelist, fps=30)

    # Write the clip to a video file using ffmpeg
    current_time = datetime.datetime.now()
    filename = "static/animate/TEMP3a.mp4"
    clip.write_videofile(filename, fps=24, codec='libx265', preset='medium')
    store = "animate/"+current_time.strftime('%Y%m%d_%H%M%S%f')[:-3] + 'june25.mp4'
    output_file = "static/animate/TEMP5.mp4"  # Replace with the desired path for the converted video file
    webm_file = "static/animate/TEMP5.webm"  # Replace with the desired path for the converted video file
    ffmpeg_cmd = ['ffmpeg', '-i', filename, '-c:v', 'libx264', '-crf', '23', '-preset', 'medium', '-c:a', 'aac', '-b:a', '128k', '-movflags', '+faststart','-y', output_file]
    subprocess.run(ffmpeg_cmd) 
    ffmpeg_cmd2 = ['ffmpeg', '-i', filename, '-c:v', 'libx264', '-crf', '23', '-preset', 'medium', '-c:a', 'aac', '-b:a', '128k', '-movflags', '+faststart', '-y', webm_file]
    subprocess.run(ffmpeg_cmd2)   
    shutil.copy(filename, store)
    return render_template('mkblend_video.html', video=filename)


@app.route('/indeX')
def indeX():
    return render_template('indeX.html')

    

@app.route('/resize_and_overlay_videos')
def resize_and_overlay_videos():
    # Path to the videos
    static_video_path = 'static/videos/2023-07-07.mp4'
    input_video_path = 'static/animate/topvideo.mp4'
    output_video_path = 'static/output/resulta.mp4'

    # Resize the input video using FFmpeg
    resize_command = f'ffmpeg -i {input_video_path} -vf "scale=410:820" -y resized.mp4'
    subprocess.call(resize_command, shell=True)

    # Overlay the resized video on the background video using FFmpeg
    overlay_command = f'ffmpeg -i {static_video_path} -i resized.mp4 -filter_complex "overlay=25:25" -y {output_video_path}'
    subprocess.call(overlay_command, shell=True)

    # Remove the temporary resized video
    subprocess.call('rm resized.mp4', shell=True)

    # Return the final video as a response
    return send_file(output_video_path, mimetype='video/mp4')


@app.route('/resize_and_overlay_videos_page')
def resize_and_overlay_videos_page():
    output_video_path = 'static/output/resulta.mp4'
    return render_template('resize_and_overlay_videos.html',video = output_video_path)

@app.route('/build_stackedvids')
def build_stackedvids():
    # Get a random video and image from the static folder
    video_filename = random.choice(glob.glob('static/square_vids/*.mp4'))
    image_filename = random.choice(glob.glob('static/squares/*.jpg'))
    
    # Load the video and image files as clips
    video_clip = VideoFileClip(video_filename)
    image_clip = ImageClip(image_filename)
    
    # Set the duration of the image clip to match the duration of the video clip
    image_clip = image_clip.set_duration(video_clip.duration)
    
    # Resize the clips to 640x640 and 640x640 respectively
    video_clip = video_clip.resize((640, 640))
    image_clip = image_clip.resize((640, 640))
    
    # Create a black clip to fill the remaining space below the image
    black_clip = ColorClip(size=(640, 640), color=(0, 0, 0)).set_duration(video_clip.duration)
    
    # Combine the clips vertically using CompositeVideoClip
    final_clip = CompositeVideoClip([
        video_clip.set_position(('center', 'top')),
        image_clip.set_position(('center', 640)),
        black_clip.set_position(('center', 640 + 640))
    ], size=(640, 1280))
    
    # Export the final clip as a video file
    timestr = time.strftime("%Y%m%d-%H%M%S")
    video_filename = 'static/stacked_vids/stacked_vids'+timestr+'video.mp4'
    final_clip_path = 'static/stacked_vids/stacked_videos.mp4'
    final_clip.write_videofile(final_clip_path)
    final_clip.write_videofile(video_filename)
    
    return render_template('/build_stackedvids.html', stackedvid_url=final_clip_path)

from moviepy.editor import *
@app.route('/build_stackedvid')
def build_stackedvid():
    # Get a random video and image from the static folder
    video_filename = random.choice(glob.glob('static/square_vids/*.mp4'))
    videofilename = random.choice(glob.glob('static/square_vids/*.mp4'))
    
    
    # Load the video and image files as clips
    video_clip = VideoFileClip(video_filename)
    videoclip = VideoFileClip(videofilename)
    
    # Set the duration of the image clip to match the duration of the video clip
    videoclip = videoclip.set_duration(video_clip.duration)
    
    # Resize the clips to 640x640 and 640x640 respectively
    video_clip = video_clip.resize((640, 640))
    videoclip = videoclip.resize((640, 640))
    
    # Create a black clip to fill the remaining space below the image
    black_clip = ColorClip(size=(640, 640), color=(0, 0, 0)).set_duration(video_clip.duration)
    
    # Combine the clips vertically using CompositeVideoClip
    final_clip = CompositeVideoClip([
        video_clip.set_position(('center', 'top')),
        videoclip.set_position(('center', 640)),
        black_clip.set_position(('center', 640 + 640))
    ], size=(640, 1280))
    
    # Export the final clip as a video file
    timestr = time.strftime("%Y%m%d-%H%M%S")
    video_filename = 'static/stacked_vids/stacked_vids'+timestr+'video.mp4'
    final_clip_path = 'static/stacked_vids/stacked_videos.mp4'
    final_clip.write_videofile(final_clip_path)
    final_clip.write_videofile(video_filename)
    
    return render_template('/build_stackedvid.html', stackedvid_url=final_clip_path)

@app.route('/clean_images', methods=['POST'])
def clean_images_route():
    clean_images()
    app.logger.error('line 210 clean_images_route')
    return redirect(url_for('index'))

@app.route('/get_gallery')
def get_gallery():
    image_dir = '/mnt/HDD500/flask/FLASK/static/images/uploads'
    image_names = os.listdir(image_dir)
    return render_template('get_gallery.html', image_names=image_names)

@app.route('/uploads/<filename>')
def send_image(filename):
    return send_from_directory('static/images/uploads', filename)

@app.route('/uploads/thumbnails/<filename>')
def send_image_thumb(filename):
    return send_from_directory('static/images/uploads/thumbnails', filename)
@app.route('/flask_info')
def flask_info():
    return render_template('flask_info.html')
@app.route('/add_effects')
def add_effects():
    return '''
        <form method="post" action="/video" enctype="multipart/form-data">
            <label for="input_video">Select input video file:</label><br>
            <input type="file" id="input_video" name="input_video"><br><br>
            <input type="submit" value="Submit">
        </form>
    '''

@app.route('/video', methods=['GET', 'POST'])
def process_video():
    DIR = "static/"
    input_video = request.files['input_video']
    
    # Save the uploaded video to a file
    input_video.save(f"{DIR}input_video.mp4")
    
    # Run FFmpeg commands
    command1 = f"ffmpeg -nostdin -i {DIR}input_video.mp4 -filter:v \"minterpolate='mi_mode=mci:mc_mode=aobmc:vsbmc=1:fps=10'\" -c:v libx264 -r 20 -pix_fmt yuv420p -c:a copy -y {DIR}output.mp4"    
    
    subprocess.run(command1, shell=True, stderr=subprocess.PIPE, universal_newlines=True)
    
    command2 = f"ffmpeg -nostdin -i {DIR}output.mp4 -vf mpdecimate,setpts=N/FRAME_RATE/TB -c:v libx264 -r 30 -pix_fmt yuv420p -c:a copy -y {DIR}mpdecimate.mp4"
    
    subprocess.run(command2, shell=True, stderr=subprocess.PIPE, universal_newlines=True)
    
    #DIR = "/home/jack/Desktop/ffmpeg_flask/"
    command3 = f"ffmpeg -i static/mpdecimate.mp4 -filter_complex \"[0:v]trim=duration=14,loop=500:1:0[v];[1:a]afade=t=in:st=0:d=1,afade=t=out:st=0.9:d=2[a1];[v][0:a][a1]concat=n=1:v=1:a=1\" -c:v libx264 -r 30 -pix_fmt yuv420p -c:a aac -b:a 192k -shortest -y static/output.mp4"
    subprocess.run(command3, shell=True, stderr=subprocess.PIPE, universal_newlines=True)
    
    now = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    shutil.copy(f"{DIR}output.mp4", f"{DIR}{now}_output.mp4")
    logging.info(f'my_video: f"{DIR}mpdecimate.mp4"') 
    video_file="static/outputALL.mp4"     
    command4 = f'ffmpeg -i "{DIR}mpdecimate.mp4" -i "{DIR}mpdecimate.mp4" -i "{DIR}mpdecimate.mp4" -i "{DIR}mpdecimate.mp4" -i "{DIR}mpdecimate.mp4" -filter_complex "[0:v]trim=duration=15[v0];[1:v]trim=duration=15[v1];[2:v]trim=duration=15[v2];[3:v]trim=duration=15[v3];[4:v]trim=duration=15[v4];[v0][v1][v2][v3][v4]concat=n=5:v=1:a=0" -c:v libx264 -pix_fmt yuv420p -shortest -y {video_file}'
    subprocess.run(command4, shell=True, stderr=subprocess.PIPE, universal_newlines=True)
    now = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    diR = f"{DIR}/square_videos/"
    logging.info(f'diR: f"{diR}mpdecimate.mp4"')
    shutil.copy(f"{video_file}", f"{diR}{now}_outputALL.mp4")
    logging.info(f'diR: {diR}mpdecimate.mp4')
    return render_template('final.html', video_file=video_file)

def get_all_mp4_videos():
    mp4_videos = []
    for root, dirs, files in os.walk('static'):
        for file in files:
            if file.endswith('.mp4'):
                mp4_videos.append(os.path.join(root, file))
    return mp4_videos

@app.route('/play/<path:video_path>')
def play(video_path):
    return send_file(video_path)

@app.route('/select_order', methods=['GET', 'POST'])
def select_order():
    output_path = 'static/videos/concatenated_video.mp4'  # Set a default value for output_path
    if request.method == 'POST':
        # Get the order of the videos from the form data
        order = request.form.getlist('order')
        # Join the videos in the specified order
        join_videos(order, output_path)
        # Set the timestamped output path
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        new_output_path = f'static/videos/concatenated_{timestamp}XX.mp4'
        shutil.copy(output_path, new_output_path)
        # Redirect to the download page
        return redirect(url_for('download'))
    else:
        # Get the paths to the video files in the directory
        video_dir = 'static/videos'
        video_files = [os.path.join(video_dir, filename) for filename in os.listdir(video_dir) if filename.endswith('.mp4')]
        # Render the template with the list of video files and the output path
        return render_template('select_order.html', video_files=video_files, output_path=output_path)
         
def join_videos(video_paths, output_path):
    # Generate a list of input arguments for FFmpeg
    input_args = []
    for path in video_paths:
        input_args.extend(['-i', path])
    # Join the videos using FFmpeg
    subprocess.run(['ffmpeg', *input_args, '-filter_complex', 'concat=n={}:v=1:a=0'.format(len(video_paths)), '-c:v', 'libx264', '-crf', '23', '-preset', 'veryfast', '-y', output_path])
    #output_path = 'static/videos/concatenated_video.mp4'
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    new_output_path = f'static/videos/concatenated_{timestamp}XX.mp4'
    shutil.copy(output_path, new_output_path)    
@app.route('/videos', methods=['POST'])
def process_videos():
    DIR = "static/"
    input_video = request.files['input_video']
    ""
    # Save the uploaded video to a file
    input_video.save(f"{DIR}input_video2.mp4")
    
    command1 = f"ffmpeg -nostdin -i {DIR}input_video2.mp4 -filter:v \"minterpolate='mi_mode=mci:mc_mode=aobmc:vsbmc=1:fps=10'\" -c:v libx264 -r 20 -pix_fmt yuv420p -c:a copy -y {DIR}alice/output2.mp4"    
    subprocess.run(command1, shell=True, stderr=subprocess.PIPE, universal_newlines=True)
    
    command2 = f"ffmpeg -hide_banner -i {DIR}alice/output2.mp4 -filter:v \"setpts=5*PTS,minterpolate='fps=25:scd=none:me_mode=bidir:vsbmc=1:search_param=200'\" -t 58 -y {DIR}alice/final2.mp4"
    subprocess.run(command2, shell=True, stderr=subprocess.PIPE, universal_newlines=True)
    
    command3 = f"ffmpeg -hide_banner -i {DIR}alice/final2.mp4 -filter:v \"setpts=5*PTS,minterpolate='fps=25:scd=none:me_mode=bidir:vsbmc=1:search_param=200'\" -t 58 -y {DIR}alice/final5.mp4"
    subprocess.run(command3, shell=True, stderr=subprocess.PIPE, universal_newlines=True)

    # Add music to the video
    command3 = f"ffmpeg -i {DIR}alice/final5.mp4 -i {DIR}long.mp3 -af 'afade=in:st=0:d=4,afade=out:st=55:d=3' -map 0:0 -map 1:0 -shortest -y {DIR}alice/Final_End.mp4"
    subprocess.run(command3, shell=True)
    
    # Save the output video to a file   
    now = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    shutil.copy(f"{DIR}alice/output2.mp4", f"{DIR}alice/{now}_output.mp4")
    shutil.copy(f"{DIR}alice/Final_End.mp4", f"{DIR}alice/{now}_Final.mp4")
    shutil.copy(f"{DIR}alice/Final_End.mp4", f"{DIR}alice/Final_End_mix.mp4")
    return render_template('final.html', video_file="alice/Final_End.mp4")
@app.route('/large_video')
def large_video():
    return render_template('large_video.html')


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5100)

