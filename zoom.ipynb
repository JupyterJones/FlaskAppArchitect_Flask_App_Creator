{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9395cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.png\n",
    "!rm *.jpg\n",
    "!rm start/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4df5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def zoom_effect(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    # Start with the original image\n",
    "    current_image = original_image.copy()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Enlarge the current image by 1%\n",
    "        new_size = (int(w * 1.01), int(h * 1.01))\n",
    "        enlarged_image = current_image.resize(new_size, Image.BICUBIC)\n",
    "        sm_size = ((int((w/w) * 1.01)+1+w), (int(h/h * 1.01))+1+h)\n",
    "        print(sm_size)\n",
    "        shrunken_image = current_image.resize(sm_size, Image.BICUBIC)        \n",
    "        # Calculate the top-left coordinates to crop back to the original size\n",
    "        x_offset = (new_size[0] - w) // 2\n",
    "        y_offset = (new_size[1] - h) // 2\n",
    "\n",
    "        # Crop back to the original size\n",
    "        cropped_image = enlarged_image.crop((x_offset, y_offset, x_offset + w, y_offset + h))\n",
    "        shrunken_image.save(\"start/\"+str(i)+\".png\")\n",
    "        # Save the current image with zoom effect\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.jpg\"\n",
    "        cropped_image = cropped_image.convert(\"RGB\")\n",
    "        cropped_image.save(output_path)\n",
    "\n",
    "        # Set the current image to the cropped image for the next iteration\n",
    "        current_image = cropped_image.copy()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 150  # Change this to the desired number of images in the sequence\n",
    "\n",
    "zoom_effect(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a new transparent image with increased size for each iteration\n",
    "        new_size = (int(w + w * inc), int(h + h * inc))\n",
    "        final_image = Image.new(\"RGBA\", new_size, (0, 0, 0, 0))\n",
    "\n",
    "        # Calculate the top-left coordinates to center the original image on the final image\n",
    "        x_offset = (new_size[0] - w) // 2\n",
    "        y_offset = (new_size[1] - h) // 2\n",
    "\n",
    "        # Paste the original image onto the final image at the calculated coordinates\n",
    "        final_image.paste(original_image, (x_offset, y_offset))\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the final image\n",
    "        x_overlay_offset = (new_size[0] - resized_original.width) // 2\n",
    "        y_overlay_offset = (new_size[1] - resized_original.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay_image = Image.new(\"RGBA\", new_size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the resized overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay_image.paste(resized_original, (x_overlay_offset, y_overlay_offset))\n",
    "\n",
    "        # Set the opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Composite the overlay image with the final image\n",
    "        final_image = Image.alpha_composite(final_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 4  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_image.width) // 2\n",
    "        y_offset = (h - overlay_image.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(resized_original, overlay)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a580b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_image.width) // 2\n",
    "        y_offset = (h - overlay_image.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(resized_original, overlay)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images, save_interval=10):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new transparent image with the same size as the original image\n",
    "        overlay_image = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, ((w - size[0]) // 2, (h - size[1]) // 2))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the transparent image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "        # Save the image at specified intervals to free up memory\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            final_image.close()\n",
    "\n",
    "    # Save the last image to ensure it is not left open\n",
    "    final_image.close()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "save_interval = 10  # Change this to adjust how often images are saved\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images, save_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d88c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6854a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the size of the overlay image based on the increase factor (inc)\n",
    "        overlay_w, overlay_h = int(w * inc), int(h * inc)\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_w) // 2\n",
    "        y_offset = (h - overlay_h) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(original_image, overlay)\n",
    "\n",
    "        # Create a zoomed version of the background image\n",
    "        zoomed_image = original_image.resize((int(w / inc), int(h / inc)), Image.BICUBIC)\n",
    "        x_zoom_offset = (w - zoomed_image.width) // 2\n",
    "        y_zoom_offset = (h - zoomed_image.height) // 2\n",
    "\n",
    "        # Paste the zoomed image onto the final image at the calculated coordinates\n",
    "        final_image.paste(zoomed_image, (x_zoom_offset, y_zoom_offset))\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new transparent image with the same size as the original image\n",
    "        overlay_image = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, ((w - size[0]) // 2, (h - size[1]) // 2))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the transparent image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Resize and set opacity for the overlay image\n",
    "        overlay_image = overlay_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with an alpha channel for overlaying\n",
    "        overlay_image = Image.new(\"RGBA\", size, (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, (0, 0))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Resize and set opacity for the overlay image\n",
    "        overlay_image = overlay_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        overlay_image = original_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        overlay_image = original_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        final_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "        x_offset = (w - size[0]) // 2\n",
    "        y_offset = (h - size[1]) // 2\n",
    "        final_image.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e89099",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls leonardo.ai_files/00001.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f75288",
   "metadata": {},
   "outputs": [],
   "source": [
    "leonardo.ai_files/00001.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7838bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_centered(larger_image_path, output_path, inc):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w, h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w - inc), int(h - inc)), Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    larger_image.save(output_path)\n",
    "\n",
    "larger_image_path = \"leonardo.ai_files/00001.jpg\"\n",
    "for Inc in range(0, 100):\n",
    "    inc = Inc + 0.5\n",
    "    output_path = str(inc) + \"test.png\"\n",
    "    print(inc)\n",
    "    overlay_centered(larger_image_path, output_path, inc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "def overlay_centered(larger_image_path, inc, image_num):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w, h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w + inc), int(h + inc)), Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    output_directory = \"start/\"\n",
    "    ext = \".png\"\n",
    "    save_path = os.path.join(output_directory, f\"{image_num:05d}{ext}\")\n",
    "    larger_image.save(save_path)\n",
    "\n",
    "\n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\"\n",
    "image_num = 1\n",
    "for inc in range(1, 1000):\n",
    "    print(inc)\n",
    "    overlay_centered(larger_image_path, inc, image_num)\n",
    "    image_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /home/jack/Desktop/learn_flask/zoom.ipynb ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def search_in_ipynb_files(root_directory, term):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        for filename in fnmatch.filter(filenames, \"*.ipynb\"):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                lines = file.readlines()\n",
    "                for line_number, line in enumerate(lines, 1):\n",
    "                    if term in line:\n",
    "                        print(f\"Found '{term}' in file: {file_path}, line: {line_number}\")\n",
    "                        print(\"XXXXXXX\",line.strip())  # Print the whole line\n",
    "\n",
    "# Example usage\n",
    "root_directory = \"/home/jack/Desktop\"\n",
    "term_to_search = \"composit\"\n",
    "search_in_ipynb_files(root_directory, term_to_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b18f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def overlay_centered(larger_image_path,inc):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w,h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w*inc),int(h*inc)),Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "    ext = \".png\"\n",
    "    output_directory = \"start/\"\n",
    "    \n",
    "    zfill = int(inc)\n",
    "    save_path = os.path.join(output_directory, f\"{zfill(5)}{ext}\")\n",
    "    larger_image.save(save_path)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save the final image\n",
    "    #larger_image.save(\"start/\"+str(inc)+\"test.png\")\n",
    "    \n",
    "    \n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\" \n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00004.jpg\" \n",
    "for inc in range(1,100):\n",
    "    inc = inc*.1\n",
    "    print(inc)\n",
    "    \n",
    "    overlay_centered(larger_image_path,inc)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6196dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef543cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_centered(larger_image_path, smaller_image_path, output_path):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    smaller_image = Image.open(smaller_image_path).convert(\"RGBA\")\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.resize((400,400),Image.BICUBIC)\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    larger_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\"\n",
    "smaller_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00004.jpg\"\n",
    "output_path = \"output_image.png\"\n",
    "\n",
    "overlay_centered(larger_image_path, smaller_image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!display output_image.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ca240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"base.png\"\n",
    "overlay_image_path = \"overlay.png\"\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0699e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/learn_flask\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52292c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Create the overlay video\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43moverlay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36moverlay_images\u001b[0;34m(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\u001b[0m\n\u001b[1;32m     27\u001b[0m     clips\u001b[38;5;241m.\u001b[39mappend(composite_clip)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Concatenate all clips to create the final video\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m final_clip \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_videoclips\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclips\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Write the video to a file\u001b[39;00m\n\u001b[1;32m     33\u001b[0m final_clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_video_path, fps\u001b[38;5;241m=\u001b[39mfps, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m'\u001b[39m, audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/compositing/concatenate.py:71\u001b[0m, in \u001b[0;36mconcatenate_videoclips\u001b[0;34m(clips, method, transition, bg_color, ismask, padding)\u001b[0m\n\u001b[1;32m     68\u001b[0m     clips \u001b[38;5;241m=\u001b[39m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m+\u001b[39m y, l) \u001b[38;5;241m+\u001b[39m [clips[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     69\u001b[0m     transition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m tt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclips\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m sizes \u001b[38;5;241m=\u001b[39m [v\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m clips]\n\u001b[1;32m     75\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sizes)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2571\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumsum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;124;03m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2569\u001b[0m \n\u001b[1;32m   2570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcumsum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = VideoFileClip(base_image_path, target_resolution=(720, 1280))\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (width * (1.0 + i * step_size), height * (1.0 + i * step_size))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    # Concatenate all clips to create the final video\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "    # Write the video to a file\n",
    "    final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/vid-from-images.mp4\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe4c38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip 0 Duration: None\n",
      "Clip 1 Duration: None\n",
      "Clip 2 Duration: None\n",
      "Clip 3 Duration: None\n",
      "Clip 4 Duration: None\n",
      "Clip 5 Duration: None\n",
      "Clip 6 Duration: None\n",
      "Clip 7 Duration: None\n",
      "Clip 8 Duration: None\n",
      "Clip 9 Duration: None\n",
      "Clip 10 Duration: None\n",
      "Clip 11 Duration: None\n",
      "Clip 12 Duration: None\n",
      "Clip 13 Duration: None\n",
      "Clip 14 Duration: None\n",
      "Clip 15 Duration: None\n",
      "Clip 16 Duration: None\n",
      "Clip 17 Duration: None\n",
      "Clip 18 Duration: None\n",
      "Clip 19 Duration: None\n",
      "Clip 20 Duration: None\n",
      "Clip 21 Duration: None\n",
      "Clip 22 Duration: None\n",
      "Clip 23 Duration: None\n",
      "Clip 24 Duration: None\n",
      "Clip 25 Duration: None\n",
      "Clip 26 Duration: None\n",
      "Clip 27 Duration: None\n",
      "Clip 28 Duration: None\n",
      "Clip 29 Duration: None\n",
      "Clip 30 Duration: None\n",
      "Clip 31 Duration: None\n",
      "Clip 32 Duration: None\n",
      "Clip 33 Duration: None\n",
      "Clip 34 Duration: None\n",
      "Clip 35 Duration: None\n",
      "Clip 36 Duration: None\n",
      "Clip 37 Duration: None\n",
      "Clip 38 Duration: None\n",
      "Clip 39 Duration: None\n",
      "Clip 40 Duration: None\n",
      "Clip 41 Duration: None\n",
      "Clip 42 Duration: None\n",
      "Clip 43 Duration: None\n",
      "Clip 44 Duration: None\n",
      "Clip 45 Duration: None\n",
      "Clip 46 Duration: None\n",
      "Clip 47 Duration: None\n",
      "Clip 48 Duration: None\n",
      "Clip 49 Duration: None\n",
      "Clip 50 Duration: None\n",
      "Error while concatenating clips: unsupported operand type(s) for +: 'int' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "import numpy as np\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = VideoFileClip(base_image_path, target_resolution=(720, 1280))\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (width * (1.0 + i * step_size), height * (1.0 + i * step_size))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Print the duration of the resized overlay clip for debugging\n",
    "        print(\"Clip\", i, \"Duration:\", resized_overlay_clip.duration)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00050.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3d845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while concatenating clips: unsupported operand type(s) for +: 'int' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00050.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ccfe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while concatenating clips: unsupported operand type(s) for +: 'int' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "        composite_clip = composite_clip.set_duration(base_clip.duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00050.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c0398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba24a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "    # Save the resulting images as a GIF animation\n",
    "    result_images[0].save('gifs/zoom_effect2.gif', save_all=True, append_images=result_images[1:], optimize=False, duration=100, loop=0)\n",
    "#zoom_effect(bg_file, fg_file)\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "zoom_effect(base_image_path, overlay_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48478ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m frames_per_second \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     38\u001b[0m images_list \u001b[38;5;241m=\u001b[39m zoom_effect(bg_file_path, fg_file_path)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcreate_mp4_from_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mp4_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_per_second\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mcreate_mp4_from_images\u001b[0;34m(images_list, output_file, fps)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mp4_from_images\u001b[39m(images_list, output_file, fps):\n\u001b[0;32m---> 28\u001b[0m     clip \u001b[38;5;241m=\u001b[39m \u001b[43mImageSequenceClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_file, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m, fps\u001b[38;5;241m=\u001b[39mfps)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/io/ImageSequenceClip.py:84\u001b[0m, in \u001b[0;36mImageSequenceClip.__init__\u001b[0;34m(self, sequence, fps, durations, with_mask, ismask, load_images)\u001b[0m\n\u001b[1;32m     82\u001b[0m    size \u001b[38;5;241m=\u001b[39m imread(sequence[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m    size \u001b[38;5;241m=\u001b[39m \u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m     87\u001b[0m     image1\u001b[38;5;241m=\u001b[39mimage\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    512\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    516\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[0;32m--> 519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "\n",
    "\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16785579",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m frames_per_second \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     36\u001b[0m images_list \u001b[38;5;241m=\u001b[39m zoom_effect(bg_file_path, fg_file_path)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mcreate_mp4_from_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mp4_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_per_second\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mcreate_mp4_from_images\u001b[0;34m(images_list, output_file, fps)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mp4_from_images\u001b[39m(images_list, output_file, fps):\n\u001b[0;32m---> 28\u001b[0m     clip \u001b[38;5;241m=\u001b[39m \u001b[43mImageSequenceClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_file, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m, fps\u001b[38;5;241m=\u001b[39mfps)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/io/ImageSequenceClip.py:84\u001b[0m, in \u001b[0;36mImageSequenceClip.__init__\u001b[0;34m(self, sequence, fps, durations, with_mask, ismask, load_images)\u001b[0m\n\u001b[1;32m     82\u001b[0m    size \u001b[38;5;241m=\u001b[39m imread(sequence[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m    size \u001b[38;5;241m=\u001b[39m \u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m     87\u001b[0m     image1\u001b[38;5;241m=\u001b[39mimage\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    512\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    516\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[0;32m--> 519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5488366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video2.mp4.\n",
      "Moviepy - Writing video output_video2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video2.mp4\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "    \n",
    "    return result_images  # Move the return statement outside the for loop\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    # Convert PIL Image objects to NumPy arrays\n",
    "    image_arrays = [np.array(image) for image in images_list]\n",
    "    \n",
    "    # Create the video clip from the NumPy arrays\n",
    "    clip = ImageSequenceClip(image_arrays, fps=fps)\n",
    "    \n",
    "    # Write the video to the output file\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00059.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00053.jpg\"\n",
    "output_mp4_file = \"output_video2.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31bd9afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m000000000121feb0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "[\u001b[32;1m00007fb4040016c0\u001b[0m] filesystem stream error: \u001b[31;1mcannot open file /home/jack/Desktop/learn_flask/output_video2 (No such file or directory)\u001b[0m\n",
      "[\u001b[32;1m00007fb420001db0\u001b[0m] filesystem stream error: \u001b[31;1mcannot open file /home/jack/Desktop/learn_flask/output_video2 (No such file or directory)\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output_video2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44f9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    # Convert PIL Image objects to NumPy arrays\n",
    "    image_arrays = [np.array(image) for image in images_list]\n",
    "    \n",
    "    # Create the video clip from the NumPy arrays\n",
    "    clip = ImageSequenceClip(image_arrays, fps=fps)\n",
    "    \n",
    "    # Write the video to the output file\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f5103c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4055: error: (-215:Assertion failed) inv_scale_x > 0 in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Create the overlay video\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43moverlay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 20\u001b[0m, in \u001b[0;36moverlay_images\u001b[0;34m(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\u001b[0m\n\u001b[1;32m     17\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(width \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m i \u001b[38;5;241m*\u001b[39m step_size)), \u001b[38;5;28mint\u001b[39m(height \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m i \u001b[38;5;241m*\u001b[39m step_size)))  \u001b[38;5;66;03m# Inverse size calculation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Resize both clips to have the same size\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m resized_base_clip \u001b[38;5;241m=\u001b[39m \u001b[43mbase_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m resized_overlay_clip \u001b[38;5;241m=\u001b[39m overlay_clip\u001b[38;5;241m.\u001b[39mresize(size)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Set the opacity of the overlay clip\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/fx/resize.py:152\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(clip, newsize, height, width, apply_to_mask)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     fl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pic: resizer(pic\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m), newsize)\n\u001b[0;32m--> 152\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfl_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to_mask \u001b[38;5;129;01mand\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m resize(clip\u001b[38;5;241m.\u001b[39mmask, newsize, apply_to_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m<decorator-gen-90>:2\u001b[0m, in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:14\u001b[0m, in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m newclip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newclip\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/VideoClip.py:936\u001b[0m, in \u001b[0;36mImageClip.fl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 936\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mimage_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t: arr\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/fx/resize.py:150\u001b[0m, in \u001b[0;36mresize.<locals>.<lambda>\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    147\u001b[0m     fl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pic: \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39mresizer((\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m pic)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m), newsize)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     fl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pic: \u001b[43mresizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m newclip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mfl_image(fl)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to_mask \u001b[38;5;129;01mand\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/fx/resize.py:16\u001b[0m, in \u001b[0;36mresizer\u001b[0;34m(pic, newsize)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# For dowsizing use area to prevent aliasing\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mly\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4055: error: (-215:Assertion failed) inv_scale_x > 0 in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    base_duration = num_steps / fps\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 - i * step_size)), int(height * (1.0 - i * step_size)))  # Inverse size calculation\n",
    "\n",
    "        # Resize both clips to have the same size\n",
    "        resized_base_clip = base_clip.resize(size)\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([resized_base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00050.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0899cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Clip Attributes: ['_TEMP_FILES_PREFIX', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'add_mask', 'afx', 'aspect_ratio', 'audio', 'audio_fadein', 'audio_fadeout', 'audio_normalize', 'blit_on', 'close', 'copy', 'crop', 'crossfadein', 'crossfadeout', 'cutout', 'duration', 'end', 'fadein', 'fadeout', 'fill_array', 'fl', 'fl_image', 'fl_time', 'fx', 'get_frame', 'h', 'has_constant_size', 'img', 'invert_colors', 'ipython_display', 'is_playing', 'ismask', 'iter_frames', 'loop', 'make_frame', 'margin', 'mask', 'mask_and', 'mask_or', 'memoize', 'memoize_frame', 'memoized_t', 'on_color', 'pos', 'preview', 'relative_pos', 'resize', 'rotate', 'save_frame', 'set_audio', 'set_duration', 'set_end', 'set_fps', 'set_ismask', 'set_make_frame', 'set_mask', 'set_memoize', 'set_opacity', 'set_pos', 'set_position', 'set_start', 'show', 'size', 'speedx', 'start', 'subclip', 'subfx', 'to_ImageClip', 'to_RGB', 'to_gif', 'to_images_sequence', 'to_mask', 'to_videofile', 'volumex', 'w', 'without_audio', 'write_gif', 'write_images_sequence', 'write_videofile']\n",
      "Base Clip Duration (Updated): 0.16666666666666669\n",
      "Concatenation successful!\n",
      "Moviepy - Building video output_video.mp4.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n",
      "Video writing successful!\n",
      "Overlay video created successfully!\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "\n",
    "    # Print the attributes of the base clip\n",
    "    print(\"Base Clip Attributes:\", dir(base_clip))\n",
    "\n",
    "    # Set the duration of the base clip to the number of steps\n",
    "    base_duration = (num_steps / fps)*.05\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    # Print the updated duration of the base clip\n",
    "    print(\"Base Clip Duration (Updated):\", base_clip.duration)\n",
    "\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00050.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4008781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m0000000001fd0eb0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f0e38001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f0e38001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f0e38001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007f0e40c12fc0\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f0e40c1a8c0] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007f0e40c12fc0\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f0e38767f40\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f0e38767f40\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f0e38767f40\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3f3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "\n",
    "    # Print the attributes of the base clip\n",
    "    print(\"Base Clip Attributes:\", dir(base_clip))\n",
    "\n",
    "    # Set the duration of the base clip to the number of steps\n",
    "    base_duration = (num_steps / fps)*.05\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    # Print the updated duration of the base clip\n",
    "    print(\"Base Clip Duration (Updated):\", base_clip.duration)\n",
    "\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1 / num_steps\n",
    "    #step_size = .25 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(1,num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        print(i)\n",
    "        if i ==0:\n",
    "            size = (1, 1)\n",
    "        else:\n",
    "            Size = (int(width * (1.0 + i * step_size))/num_steps, int(height * (1.0 + i * step_size))/num_steps)\n",
    "            print(Size)\n",
    "        size = (i*10),(i*10)\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00050.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1e768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m0000000001dc7eb0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fcff4001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fcff4001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fcff4001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007fd004c02170\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7fd004c16e40] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007fd004c02170\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fcff475f280\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fcff475f280\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fcff475f280\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa02db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloned-base",
   "language": "python",
   "name": "cloned-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
