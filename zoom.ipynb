{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir zooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/jack/Desktop/HDD500/collections/Music/Blue_Mood-Robert_Munzinger.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f9169",
   "metadata": {},
   "source": [
    "# Audio_Fade in and out working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a656a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video steampunk/slideshowSharp-music.mp4.\n",
      "MoviePy - Writing audio in slideshowSharp-musicTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video steampunk/slideshowSharp-music.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready steampunk/slideshowSharp-music.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"steampunk/slideshowSharp.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Ensure the audio clip is the same duration as the video\n",
    "if audio_clip.duration > video_clip.duration:\n",
    "    audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "else:\n",
    "    padding_duration = video_clip.duration - audio_clip.duration\n",
    "    padding = AudioFileClip.silence(duration=padding_duration)\n",
    "    audio_clip = concatenate_audioclips([audio_clip, padding])\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = faded_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"steampunk/slideshowSharp-music.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b4cb2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m000000000158d1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fed34001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fed34001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fed34001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007fed58d98580\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7fed58da91c0] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007fed58d98580\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fed34766900\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fed34766900\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fed34766900\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc steampunk/slideshowSharp-music.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8236fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-liblensfun --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/steampunk.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:02:21.04, start: 0.000000, bitrate: 589 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 768x512, 455 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(und): Audio: mp3 (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0musing cpu capabilities: MMX2 SSE2Fast LZCNT SSSE3 SSE4.2\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mprofile High, level 3.0\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Sharpensteampunk.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 768x512, q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1(und): Audio: mp3 (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "frame= 3525 fps=101 q=-1.0 Lsize=   11474kB time=00:02:20.98 bitrate= 666.7kbits/s speed=4.03x    \n",
      "video:9153kB audio:2204kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.034800%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mframe I:15    Avg QP:17.26  size: 92931\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mframe P:2100  Avg QP:22.24  size:  3779\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mframe B:1410  Avg QP:29.75  size:    30\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mconsecutive B-frames: 45.8%  1.1%  4.8% 48.3%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mmb I  I16..4:  1.3% 86.1% 12.7%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mmb P  I16..4:  0.1%  2.0%  0.9%  P16..4: 15.9%  1.7%  1.6%  0.0%  0.0%    skip:77.6%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.5%  0.0%  0.0%  direct: 0.0%  skip:99.5%  L0:35.4% L1:64.4% BI: 0.2%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0m8x8 transform intra:69.9% inter:64.9%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mcoded y,uvDC,uvAC intra: 94.1% 94.5% 77.4% inter: 2.6% 8.5% 0.3%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mi16 v,h,dc,p: 35% 52%  1% 12%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 18% 12%  6%  6%  7%  9%  8% 11%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 19% 12%  6%  7%  7%  8%  6%  8%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mi8c dc,h,v,p: 44% 22% 25%  9%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mref P L0: 84.1%  4.0%  9.7%  2.2%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mref B L0: 94.3%  5.6%  0.1%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mref B L1: 87.3% 12.7%\n",
      "\u001b[1;36m[libx264 @ 0x55b444c90000] \u001b[0mkb/s:531.75\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/steampunk.mp4 -vf \"unsharp=5:5:1.0:5:5:0.0\" -c:a copy /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Sharpensteampunk.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87143e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/StoryMaker\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e771fd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/images/Elektra-Weapons/SSsteampunk-5-9nk.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Call the sharpen_video function\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43msharpen_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust strength as needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36msharpen_video\u001b[0;34m(input_path, output_path, strength)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sharpened_frame\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Apply the custom effect to each frame of the video\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfl_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43msharpen_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Set the audio\u001b[39;00m\n\u001b[1;32m     20\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m sharpened_clip\u001b[38;5;241m.\u001b[39mset_audio(video_clip\u001b[38;5;241m.\u001b[39maudio)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/VideoClip.py:490\u001b[0m, in \u001b[0;36mVideoClip.fl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mModifies the images of a clip by replacing the frame\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m`get_frame(t)` by another frame,  `image_func(get_frame(t))`\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m apply_to \u001b[38;5;241m=\u001b[39m apply_to \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m--> 490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:136\u001b[0m, in \u001b[0;36mClip.fl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    133\u001b[0m     apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#mf = copy(self.make_frame)\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_make_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_duration:\n\u001b[1;32m    139\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-79>:2\u001b[0m, in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:14\u001b[0m, in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m newclip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newclip\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/VideoClip.py:644\u001b[0m, in \u001b[0;36mVideoClip.set_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Change the clip's ``get_frame``.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03mReturns a copy of the VideoClip instance, with the make_frame\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03mattribute set to `mf`.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m mf\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:136\u001b[0m, in \u001b[0;36mClip.fl.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    133\u001b[0m     apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#mf = copy(self.make_frame)\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_make_frame(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_duration:\n\u001b[1;32m    139\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/VideoClip.py:490\u001b[0m, in \u001b[0;36mVideoClip.fl_image.<locals>.<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mModifies the images of a clip by replacing the frame\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m`get_frame(t)` by another frame,  `image_func(get_frame(t))`\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m apply_to \u001b[38;5;241m=\u001b[39m apply_to \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m--> 490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfl(\u001b[38;5;28;01mlambda\u001b[39;00m gf, t: \u001b[43mimage_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, apply_to)\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36msharpen_video.<locals>.sharpen_frame\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msharpen_frame\u001b[39m(t):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Get the frame at time t\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Apply sharpening to the frame\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     sharpened_frame \u001b[38;5;241m=\u001b[39m frame \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m+\u001b[39m strength)\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/io/VideoFileClip.py:113\u001b[0m, in \u001b[0;36mVideoFileClip.__init__.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Make a reader for the audio, if any.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39minfos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_found\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/io/ffmpeg_reader.py:169\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Read a file video frame at time t.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mNote for coders: getting an arbitrary frame in the video with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mwhenever possible, by moving between adjacent frames.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# these definitely need to be rechecked sometime. Seems to work.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# I use that horrible '+0.00001' hack because sometimes due to numerical\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# imprecisions a 3.0 can become a 2.99999999... which makes the int()\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# go to the previous integer. This makes the fetching more robust in the\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# case where you get the nth frame by writing get_frame(n/fps).\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Initialize proc if it is not open\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc:\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def sharpen_video(input_path, output_path, strength):\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(input_path)\n",
    "\n",
    "    # Define a custom video effect to apply sharpening\n",
    "    def sharpen_frame(t):\n",
    "        # Get the frame at time t\n",
    "        frame = video_clip.get_frame(t)\n",
    "\n",
    "        # Apply sharpening to the frame\n",
    "        sharpened_frame = frame * (0.5 + strength)\n",
    "        return sharpened_frame\n",
    "\n",
    "    # Apply the custom effect to each frame of the video\n",
    "    sharpened_clip = video_clip.fl_image(sharpen_frame)\n",
    "\n",
    "    # Set the audio\n",
    "    sharpened_clip = sharpened_clip.set_audio(video_clip.audio)\n",
    "\n",
    "    # Write the processed video to a new file\n",
    "    sharpened_clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_video_path = 'static/images/Elektra-Weapons/steampunk.mp4'\n",
    "output_video_path = 'static/images/Elektra-Weapons/SSsteampunk-5-9nk.mp4'\n",
    "\n",
    "# Call the sharpen_video function\n",
    "sharpen_video(input_video_path, output_video_path, strength=0.9)  # Adjust strength as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "699a9336",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sharpen_frame() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/images/Elektra-Weapons/SSsteampunk-5-nkl.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Call the sharpen_video function\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43msharpen_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust strength as needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36msharpen_video\u001b[0;34m(input_path, output_path, strength)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sharpened_frame\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Apply the custom effect to each frame of the video\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msharpen_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Set the audio\u001b[39;00m\n\u001b[1;32m     20\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m sharpened_clip\u001b[38;5;241m.\u001b[39mset_audio(video_clip\u001b[38;5;241m.\u001b[39maudio)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:136\u001b[0m, in \u001b[0;36mClip.fl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    133\u001b[0m     apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#mf = copy(self.make_frame)\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_make_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_duration:\n\u001b[1;32m    139\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-79>:2\u001b[0m, in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:14\u001b[0m, in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m newclip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newclip\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/VideoClip.py:644\u001b[0m, in \u001b[0;36mVideoClip.set_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Change the clip's ``get_frame``.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03mReturns a copy of the VideoClip instance, with the make_frame\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03mattribute set to `mf`.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m mf\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:136\u001b[0m, in \u001b[0;36mClip.fl.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    133\u001b[0m     apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#mf = copy(self.make_frame)\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_make_frame(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_duration:\n\u001b[1;32m    139\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: sharpen_frame() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def sharpen_video(input_path, output_path, strength):\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(input_path)\n",
    "\n",
    "    # Define a custom video effect to apply sharpening\n",
    "    def sharpen_frame(t):\n",
    "        # Get the frame at time t\n",
    "        frame = video_clip.get_frame(t)\n",
    "\n",
    "        # Apply sharpening to the frame\n",
    "        sharpened_frame = frame * (0.5 + strength)\n",
    "        return sharpened_frame\n",
    "\n",
    "    # Apply the custom effect to each frame of the video\n",
    "    sharpened_clip = video_clip.fl(sharpen_frame)\n",
    "\n",
    "    # Set the audio\n",
    "    sharpened_clip = sharpened_clip.set_audio(video_clip.audio)\n",
    "\n",
    "    # Write the processed video to a new file\n",
    "    sharpened_clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_video_path = 'static/images/Elektra-Weapons/steampunk.mp4'\n",
    "output_video_path = 'static/images/Elektra-Weapons/SSsteampunk-5-nkl.mp4'\n",
    "\n",
    "# Call the sharpen_video function\n",
    "sharpen_video(input_video_path, output_video_path, strength=0.9)  # Adjust strength as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f283d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video static/images/Elektra-Weapons/SSsteampunk-5-9.mp4.\n",
      "MoviePy - Writing audio in SSsteampunk-5-9TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video static/images/Elektra-Weapons/SSsteampunk-5-9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready static/images/Elektra-Weapons/SSsteampunk-5-9.mp4\n"
     ]
    }
   ],
   "source": [
    "# save this\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def sharpen_video(input_path, output_path, strength):\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(input_path)\n",
    "\n",
    "    # Define a custom video effect to apply sharpening\n",
    "    def sharpen_frame(frame):\n",
    "        # Apply sharpening to the frame\n",
    "        #sharpened_frame = frame * (1 + strength)\n",
    "        sharpened_frame = frame * (.5 + strength)\n",
    "        return sharpened_frame\n",
    "\n",
    "    # Apply the custom effect to each frame of the video\n",
    "    sharpened_clip = video_clip.fl(lambda gf, t: sharpen_frame(gf(t)))\n",
    "\n",
    "    # Set the audio\n",
    "    sharpened_clip = sharpened_clip.set_audio(video_clip.audio)\n",
    "\n",
    "    # Write the processed video to a new file\n",
    "    sharpened_clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_video_path = 'static/images/Elektra-Weapons/steampunk.mp4'\n",
    "output_video_path = 'static/images/Elektra-Weapons/SSsteampunk-5-9.mp4'\n",
    "\n",
    "# Call the sharpen_video function\n",
    "sharpen_video(input_video_path, output_video_path, strength=0.9)  # Adjust strength as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06bdde08",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'moviepy.video.fx' has no attribute 'vfx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/images/Elektra-Weapons/SSsteampunk-5-n.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Call the sharpen_video function\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43msharpen_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust strength as needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36msharpen_video\u001b[0;34m(input_path, output_path, strength)\u001b[0m\n\u001b[1;32m      6\u001b[0m video_clip \u001b[38;5;241m=\u001b[39m VideoFileClip(input_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the sharpening effect using the vfx.sharpen function\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m video_clip\u001b[38;5;241m.\u001b[39mfx(\u001b[43mfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvfx\u001b[49m\u001b[38;5;241m.\u001b[39msharpen, strength)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Write the processed video to a new file\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sharpened_clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_path, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m'\u001b[39m, audio_codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'moviepy.video.fx' has no attribute 'vfx'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video import fx\n",
    "\n",
    "def sharpen_video(input_path, output_path, strength=1.0):\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(input_path)\n",
    "\n",
    "    # Apply the sharpening effect using the vfx.sharpen function\n",
    "    sharpened_clip = video_clip.fx(fx.vfx.sharpen, strength)\n",
    "\n",
    "    # Write the processed video to a new file\n",
    "    sharpened_clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_video_path = 'static/images/Elektra-Weapons/steampunk.mp4'\n",
    "output_video_path = 'static/images/Elektra-Weapons/SSsteampunk-5-n.mp4'\n",
    "\n",
    "# Call the sharpen_video function\n",
    "sharpen_video(input_video_path, output_video_path, strength=0.5)  # Adjust strength as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6955e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m00000000013761a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6124001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6124001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6124001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007f6150d960b0\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f6150da6c40] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007f6150d960b0\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6124759930\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6124759930\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6124759930\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f6150da6c40] \u001b[0m\u001b[1;31mget_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f6150da6c40] \u001b[0m\u001b[1;31mthread_get_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f6150da6c40] \u001b[0m\u001b[1;31mdecode_slice_header error\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f6150da6c40] \u001b[0m\u001b[1;31mno frame!\n",
      "\u001b[0mQObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc static/images/Elektra-Weapons/SSsteampunk-5-9.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20a472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cc4199",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/images/Elektra-Weapons/Ssharpened_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Call the sharpen_video function\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43msharpen_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust strength as needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36msharpen_video\u001b[0;34m(input_path, output_path, strength)\u001b[0m\n\u001b[1;32m      6\u001b[0m video_clip \u001b[38;5;241m=\u001b[39m VideoFileClip(input_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the sharpening effect\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstrength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Set the audio\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sharpened_clip \u001b[38;5;241m=\u001b[39m sharpened_clip\u001b[38;5;241m.\u001b[39mset_audio(video_clip\u001b[38;5;241m.\u001b[39maudio)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/Clip.py:212\u001b[0m, in \u001b[0;36mClip.fx\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfx\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    Returns the result of ``func(self, *args, **kwargs)``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx import resize\n",
    "\n",
    "def sharpen_video(input_path, output_path, strength=1.0):\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(input_path)\n",
    "\n",
    "    # Apply the sharpening effect\n",
    "    sharpened_clip = video_clip.fx(resize, lambda t: 1 + strength)\n",
    "\n",
    "    # Set the audio\n",
    "    sharpened_clip = sharpened_clip.set_audio(video_clip.audio)\n",
    "\n",
    "    # Write the processed video to a new file\n",
    "    sharpened_clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_video_path = 'static/images/Elektra-Weapons/steampunk.mp4'\n",
    "output_video_path = 'static/images/Elektra-Weapons/Ssharpened_video.mp4'\n",
    "\n",
    "# Call the sharpen_video function\n",
    "sharpen_video(input_video_path, output_video_path, strength=0.5)  # Adjust strength as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e793d8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m00000000011ba1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f765c001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f765c001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f765c001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007f767cd98330\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f767cda8e80] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007f767cd98330\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f765c7662e0\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f765c7662e0\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f765c7662e0\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Sharpensteampunk.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6887b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Ensure the audio clip is the same duration as the video\n",
    "if audio_clip.duration > video_clip.duration:\n",
    "    audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "else:\n",
    "    padding_duration = video_clip.duration - audio_clip.duration\n",
    "    padding = AudioFileClip.silence(duration=padding_duration)\n",
    "    audio_clip = concatenate_audioclips([audio_clip, padding])\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = faded_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed-test.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Ensure the audio clip is the same duration as the video\n",
    "if audio_clip.duration > video_clip.duration:\n",
    "    audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "else:\n",
    "    padding_duration = video_clip.duration - audio_clip.duration\n",
    "    padding = AudioFileClip.silence(duration=padding_duration)\n",
    "    audio_clip = concatenate_audioclips([audio_clip, padding])\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 15  # seconds\n",
    "fade_out_duration = 10  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = faded_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Load the image overlay\n",
    "overlay_image = ImageClip(\"/home/jack/Desktop/StoryMaker/static/assets/Glitch_Art_Frame_512x768.png\")\n",
    "\n",
    "# Resize the overlay image to match the video dimensions\n",
    "overlay_image = overlay_image.resize(width=video_with_audio.w, height=video_with_audio.h)\n",
    "\n",
    "# Set the duration of the overlay image to match the video duration\n",
    "overlay_image = overlay_image.set_duration(video_with_audio.duration)\n",
    "\n",
    "# Composite the video with the overlay image\n",
    "final_video = CompositeVideoClip([video_with_audio, overlay_image])\n",
    "\n",
    "# Write the final video with audio and overlay to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4\"\n",
    "final_video.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = synced_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Get the minimum duration between video and audio\n",
    "min_duration = min(video_with_audio.duration, synced_audio.duration)\n",
    "\n",
    "# Set video and audio to desired duration\n",
    "video_duration = 58  # seconds\n",
    "video_with_audio = video_with_audio.subclip(0, min(video_duration, min_duration))\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dc028",
   "metadata": {},
   "source": [
    "# Generate Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, AudioClip\n",
    "import numpy as np\n",
    "\n",
    "make_frame = lambda t: np.sin(440 * 2 * np.pi * t)\n",
    "clip = AudioClip(make_frame, duration=.5, fps=44100)\n",
    "clip.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plays the note A in mono (a sine wave of frequency 440 Hz)\n",
    "import numpy as np\n",
    "\n",
    "# Plays the note A in stereo (two sine waves of frequencies 440 and 880 Hz)\n",
    "make_frame = lambda t: np.array([\n",
    "    np.sin(440 * 2 * np.pi * t),\n",
    "    np.sin(880 * 2 * np.pi * t)\n",
    "]).T.copy(order=\"C\")\n",
    "clip = AudioClip(make_frame, duration=3, fps=44100)\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import subprocess\n",
    "\n",
    "# Generate the stereo audio clip\n",
    "def make_frame(t):\n",
    "    return np.array([\n",
    "        np.sin(440 * 2 * np.pi * t),\n",
    "        np.sin(880 * 2 * np.pi * t)\n",
    "    ]).T.copy(order=\"C\")\n",
    "\n",
    "duration = 3  # seconds\n",
    "fps = 44100\n",
    "sample_rate = 44100\n",
    "num_channels = 2\n",
    "num_samples = int(sample_rate * duration)\n",
    "audio_data = np.array([make_frame(t) for t in np.linspace(0, duration, num_samples)])\n",
    "\n",
    "# Save the audio data as a WAV file\n",
    "wavfile.write(\"zooms/tone.wav\", sample_rate, audio_data)\n",
    "\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"zooms/tone.wav\", \"zooms/tone.mp3\"])\n",
    "\n",
    "print(\"Audio saved as tone.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0898cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creates a small transparent overlay that as it get larger increates in opacity \n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import uuid\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "    \n",
    "    # Save the resulting images as a GIF animation\n",
    "    result_images[0].save('gifs/zoom_effect2.gif', save_all=True, append_images=result_images[1:], optimize=False, duration=100, loop=0)\n",
    "\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "zoom_effect(base_image_path, overlay_image_path)\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "base_filename = str(uuid.uuid4())\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"gifs/zoom_effect2.gif\", \"gifs/\"+base_filename+\".mp4\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a07ffc",
   "metadata": {},
   "source": [
    "# All above is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150de035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Load the audio clip\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "audio_start_time = max(58 - faded_audio.duration, 20)\n",
    "\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "audio_clip = synced_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Trim the audio clip to exactly 58 seconds\n",
    "final_audio_clip = audio_clip.subclip(0, 58)\n",
    "\n",
    "print(\"Audio clip duration:\", final_audio_clip.duration, \"seconds\")\n",
    "final_audio_clip.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "import uuid\n",
    "import glob\n",
    "import random\n",
    "# Function to find a random song in the Music directory\n",
    "def music():\n",
    "    MUSIC = random.choice(glob.glob(\"/home/jack/Desktop/HDD500/collections/Music/*.mp3\"))\n",
    "    return MUSIC\n",
    "\n",
    "audio_clip = AudioFileClip(music())  # Replace with your audio file path\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 10  # seconds\n",
    "\n",
    "# Calculate the maximum possible start time to ensure the selected section fits within the audio clip\n",
    "max_start_time = audio_clip.duration - (58 - fade_in_duration - fade_out_duration)\n",
    "\n",
    "# Choose a random start time within the valid range\n",
    "random_start_time = random.uniform(0, max_start_time)\n",
    "\n",
    "# Calculate the end time based on the random start time and desired total duration\n",
    "random_end_time = random_start_time + (58 - fade_out_duration)\n",
    "\n",
    "# Extract the random section from the audio clip\n",
    "random_section = audio_clip.subclip(random_start_time, random_end_time)\n",
    "\n",
    "# Apply fade-in and fade-out effects\n",
    "faded_audio = random_section.audio_fadein(fade_in_duration).audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Make sure the resulting audio clip is exactly 58 seconds long\n",
    "final_audio_clip = faded_audio.subclip(0, 58)\n",
    "\n",
    "# Print the duration of the final audio clip\n",
    "print(\"Final audio clip duration:\", final_audio_clip.duration, \"seconds\")\n",
    "\n",
    "# Preview the final audio clip\n",
    "final_audio_clip.preview()\n",
    "\n",
    "base_filename = str(uuid.uuid4())\n",
    "# Save the audio as a WAV file\n",
    "clip=final_audio_clip\n",
    "wavfile.write(\"zooms/\"+base_filename+\".wav\", int(clip.fps), clip.to_soundarray())\n",
    "import subprocess\n",
    "\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"zooms/\"+base_filename+\".wav\", \"zooms/\"+base_filename+\".mp3\"])\n",
    "\n",
    "print(\"Audio saved as zooms/\"+base_filename+\".wav\")\n",
    "\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc zooms/audio02b.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "# Save an audio clip as a WAV file\n",
    "clip=final_audio_clip\n",
    "wavfile.write(\"zooms/audio02.wav\", int(clip.fps), clip.to_soundarray())\n",
    "import subprocess\n",
    "\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"zooms/audio02.wav\", \"zooms/audio02.mp3\"])\n",
    "\n",
    "print(\"Audio saved as zooms/audio02.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working but not wanted\n",
    "from moviepy.editor import VideoFileClip\n",
    "import random\n",
    "\n",
    "# Load the video clip\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "\n",
    "# Define the desired duration of the random section\n",
    "desired_duration = 1  # seconds\n",
    "\n",
    "# Calculate the maximum possible start time to ensure the selected section fits within the video\n",
    "max_start_time = video_clip.duration - desired_duration\n",
    "\n",
    "# Choose a random start time within the valid range\n",
    "random_start_time = random.uniform(0, max_start_time)\n",
    "\n",
    "# Extract the random section from the video\n",
    "random_section = video_clip.subclip(random_start_time, random_start_time + desired_duration)\n",
    "\n",
    "# Print the duration of the random section\n",
    "print(\"Random section duration:\", random_section.duration, \"seconds\")\n",
    "\n",
    "# Preview the random section\n",
    "random_section.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c96b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, AudioClip\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "\n",
    "#audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "audio_start_time = max(58 - faded_audio.duration, 20)\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "audio_clip = synced_audio.audio_fadeout(fade_out_duration)\n",
    "print(\"Audio clip duration:\", audio_clip.duration, \"seconds\")\n",
    "audio_clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Load the audio clip\n",
    "audio_clip = AudioFileClip(\"your_audio_file.mp3\")  # Replace with your audio file path\n",
    "\n",
    "# Print the duration of the audio clip\n",
    "print(\"Audio clip duration:\", audio_clip.duration, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc zooms/audio01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.fx(audio_fadein, \"00:00:06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/abd0aebb-ce72-4a30-a233-14ee14f5b841random_video_58s.mp4\")\n",
    "clip = AudioFileClip(music())\n",
    "clip.fx(audio_fadein, \"00:00:10\")\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = AudioFileClip(music())\n",
    "\n",
    "clip.fx(audio_fadein, \"00:00:26\")\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import moviepy.audio.fx.all as afx\n",
    "clip = AudioFileClip(music())\n",
    "\n",
    "clip.fx(afx.audio_fadein, \"00:00:26\")\n",
    "\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "clip = AudioFileClip(music())\n",
    "clip.fx(audio_fadein, \"00:00:06\")\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "Cell In[43], line 3\n",
    "      1 clip = AudioFileClip(music())\n",
    "----> 3 clip.fx(audio_fadein, \"00:00:06\")\n",
    "\n",
    "NameError: name 'audio_fadein' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/abd0aebb-ce72-4a30-a233-14ee14f5b841random_video_58s.mp4\")\n",
    "clip = AudioFileClip(music())\n",
    "\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 1  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "clip.fx(audio_fadein, \"00:00:20\")\n",
    "clip.preview()\n",
    "\n",
    "\n",
    "#faded_audio = audio_clip.fx.fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "#audio_start_time = max(video_clip.duration - faded_audio.duration, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 5  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_fadein(audio_clip, fade_in_duration)\n",
    "\n",
    "# Trim the audio to match the video duration\n",
    "trimmed_audio = faded_audio.subclip(0, video_clip.duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = trimmed_audio.audio_fadeout(trimmed_audio, fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zommed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043916f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 5  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = synced_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, duration=58,codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c449470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166babd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/abd0aebb-ce72-4a30-a233-14ee14f5b841random_video_58s.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 1  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Fade in audio\n",
    "faded_audio = audio_clip.crossfadein(fade_in_duration)\n",
    "\n",
    "# Calculate the point at which to start audio to synchronize with the video\n",
    "audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "\n",
    "# Trim audio to match video duration\n",
    "trimmed_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Concatenate video with trimmed audio\n",
    "video_with_audio = video_clip.set_audio(trimmed_audio)\n",
    "\n",
    "# Fade out audio at the end of the video\n",
    "final_audio = video_with_audio.audio.crossfadeout(fade_out_duration)\n",
    "\n",
    "# Set the audio of the video to the faded-out audio\n",
    "final_video = video_with_audio.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "final_video.write_videofile(\"/home/jack/Desktop/StoryMaker/VIDEOS/uuidoutput.mp4\", codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43247b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /home/jack/hidden/MUSIC.py\n",
    "import glob\n",
    "import random\n",
    "def music():\n",
    "    MUSIC = random.choice(glob.glob(\"/home/jack/Desktop/HDD500/collections/Music/*.mp3\"))\n",
    "    return MUSIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MUSIC import music\n",
    "print (music())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9395cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.png\n",
    "!rm *.jpg\n",
    "!rm start/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4df5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def zoom_effect(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    # Start with the original image\n",
    "    current_image = original_image.copy()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Enlarge the current image by 1%\n",
    "        new_size = (int(w * 1.01), int(h * 1.01))\n",
    "        enlarged_image = current_image.resize(new_size, Image.BICUBIC)\n",
    "        sm_size = ((int((w/w) * 1.01)+1+w), (int(h/h * 1.01))+1+h)\n",
    "        print(sm_size)\n",
    "        shrunken_image = current_image.resize(sm_size, Image.BICUBIC)        \n",
    "        # Calculate the top-left coordinates to crop back to the original size\n",
    "        x_offset = (new_size[0] - w) // 2\n",
    "        y_offset = (new_size[1] - h) // 2\n",
    "\n",
    "        # Crop back to the original size\n",
    "        cropped_image = enlarged_image.crop((x_offset, y_offset, x_offset + w, y_offset + h))\n",
    "        shrunken_image.save(\"start/\"+str(i)+\".png\")\n",
    "        # Save the current image with zoom effect\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.jpg\"\n",
    "        cropped_image = cropped_image.convert(\"RGB\")\n",
    "        cropped_image.save(output_path)\n",
    "\n",
    "        # Set the current image to the cropped image for the next iteration\n",
    "        current_image = cropped_image.copy()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 150  # Change this to the desired number of images in the sequence\n",
    "\n",
    "zoom_effect(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_image.width) // 2\n",
    "        y_offset = (h - overlay_image.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(resized_original, overlay)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a580b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_image.width) // 2\n",
    "        y_offset = (h - overlay_image.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(resized_original, overlay)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images, save_interval=10):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new transparent image with the same size as the original image\n",
    "        overlay_image = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, ((w - size[0]) // 2, (h - size[1]) // 2))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the transparent image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "        # Save the image at specified intervals to free up memory\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            final_image.close()\n",
    "\n",
    "    # Save the last image to ensure it is not left open\n",
    "    final_image.close()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "save_interval = 10  # Change this to adjust how often images are saved\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images, save_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d88c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6854a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the size of the overlay image based on the increase factor (inc)\n",
    "        overlay_w, overlay_h = int(w * inc), int(h * inc)\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_w) // 2\n",
    "        y_offset = (h - overlay_h) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(original_image, overlay)\n",
    "\n",
    "        # Create a zoomed version of the background image\n",
    "        zoomed_image = original_image.resize((int(w / inc), int(h / inc)), Image.BICUBIC)\n",
    "        x_zoom_offset = (w - zoomed_image.width) // 2\n",
    "        y_zoom_offset = (h - zoomed_image.height) // 2\n",
    "\n",
    "        # Paste the zoomed image onto the final image at the calculated coordinates\n",
    "        final_image.paste(zoomed_image, (x_zoom_offset, y_zoom_offset))\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new transparent image with the same size as the original image\n",
    "        overlay_image = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, ((w - size[0]) // 2, (h - size[1]) // 2))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the transparent image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Resize and set opacity for the overlay image\n",
    "        overlay_image = overlay_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with an alpha channel for overlaying\n",
    "        overlay_image = Image.new(\"RGBA\", size, (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, (0, 0))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "        DIR = \"zooms/\"\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{DIR}{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00007.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir zooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ca005",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Resize and set opacity for the overlay image\n",
    "        overlay_image = overlay_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        overlay_image = original_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        overlay_image = original_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        final_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "        x_offset = (w - size[0]) // 2\n",
    "        y_offset = (h - size[1]) // 2\n",
    "        final_image.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e89099",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls leonardo.ai_files/00001.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f75288",
   "metadata": {},
   "outputs": [],
   "source": [
    "leonardo.ai_files/00001.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7838bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_centered(larger_image_path, output_path, inc):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w, h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w - inc), int(h - inc)), Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    larger_image.save(output_path)\n",
    "\n",
    "larger_image_path = \"leonardo.ai_files/00001.jpg\"\n",
    "for Inc in range(0, 100):\n",
    "    inc = Inc + 0.5\n",
    "    output_path = str(inc) + \"test.png\"\n",
    "    print(inc)\n",
    "    overlay_centered(larger_image_path, output_path, inc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "def overlay_centered(larger_image_path, inc, image_num):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w, h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w + inc), int(h + inc)), Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    output_directory = \"start/\"\n",
    "    ext = \".png\"\n",
    "    save_path = os.path.join(output_directory, f\"{image_num:05d}{ext}\")\n",
    "    larger_image.save(save_path)\n",
    "\n",
    "\n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\"\n",
    "image_num = 1\n",
    "for inc in range(1, 1000):\n",
    "    print(inc)\n",
    "    overlay_centered(larger_image_path, inc, image_num)\n",
    "    image_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /home/jack/Desktop/learn_flask/zoom.ipynb ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def search_in_ipynb_files(root_directory, term):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        for filename in fnmatch.filter(filenames, \"*.ipynb\"):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                lines = file.readlines()\n",
    "                for line_number, line in enumerate(lines, 1):\n",
    "                    if term in line:\n",
    "                        print(f\"Found '{term}' in file: {file_path}, line: {line_number}\")\n",
    "                        print(\"XXXXXXX\",line.strip())  # Print the whole line\n",
    "\n",
    "# Example usage\n",
    "root_directory = \"/home/jack/Desktop\"\n",
    "term_to_search = \"composit\"\n",
    "search_in_ipynb_files(root_directory, term_to_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b18f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def overlay_centered(larger_image_path,inc):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w,h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w*inc),int(h*inc)),Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "    ext = \".png\"\n",
    "    output_directory = \"start/\"\n",
    "    \n",
    "    zfill = int(inc)\n",
    "    save_path = os.path.join(output_directory, f\"{zfill(5)}{ext}\")\n",
    "    larger_image.save(save_path)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save the final image\n",
    "    #larger_image.save(\"start/\"+str(inc)+\"test.png\")\n",
    "    \n",
    "    \n",
    "larger_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\" \n",
    "larger_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\" \n",
    "for inc in range(1,100):\n",
    "    inc = inc*.1\n",
    "    print(inc)\n",
    "    \n",
    "    overlay_centered(larger_image_path,inc)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6196dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef543cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_centered(larger_image_path, smaller_image_path, output_path):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    smaller_image = Image.open(smaller_image_path).convert(\"RGBA\")\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.resize((400,400),Image.BICUBIC)\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    larger_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\"\n",
    "smaller_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00004.jpg\"\n",
    "output_path = \"output_image.png\"\n",
    "\n",
    "overlay_centered(larger_image_path, smaller_image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!display output_image.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ca240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0699e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52292c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = VideoFileClip(base_image_path, target_resolution=(720, 1280))\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (width * (1.0 + i * step_size), height * (1.0 + i * step_size))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    # Concatenate all clips to create the final video\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "    # Write the video to a file\n",
    "    final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/vid-from-images.mp4\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "import numpy as np\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = VideoFileClip(base_image_path, target_resolution=(720, 1280))\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (width * (1.0 + i * step_size), height * (1.0 + i * step_size))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Print the duration of the resized overlay clip for debugging\n",
    "        print(\"Clip\", i, \"Duration:\", resized_overlay_clip.duration)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"xooms/output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"zooms/output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7b72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ccfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "        composite_clip = composite_clip.set_duration(base_clip.duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"zooms/output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "    # Save the resulting images as a GIF animation\n",
    "    result_images[0].save('gifs/zoom_effect2.gif', save_all=True, append_images=result_images[1:], optimize=False, duration=100, loop=0)\n",
    "#zoom_effect(bg_file, fg_file)\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "zoom_effect(base_image_path, overlay_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "\n",
    "\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16785579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "    \n",
    "    return result_images  # Move the return statement outside the for loop\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    # Convert PIL Image objects to NumPy arrays\n",
    "    image_arrays = [np.array(image) for image in images_list]\n",
    "    \n",
    "    # Create the video clip from the NumPy arrays\n",
    "    clip = ImageSequenceClip(image_arrays, fps=fps)\n",
    "    \n",
    "    # Write the video to the output file\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "fg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_mp4_file = \"output_video2.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc output_video2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    # Convert PIL Image objects to NumPy arrays\n",
    "    image_arrays = [np.array(image) for image in images_list]\n",
    "    \n",
    "    # Create the video clip from the NumPy arrays\n",
    "    clip = ImageSequenceClip(image_arrays, fps=fps)\n",
    "    \n",
    "    # Write the video to the output file\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "fg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5103c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    base_duration = num_steps / fps\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 - i * step_size)), int(height * (1.0 - i * step_size)))  # Inverse size calculation\n",
    "\n",
    "        # Resize both clips to have the same size\n",
    "        resized_base_clip = base_clip.resize(size)\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([resized_base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3f3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "\n",
    "    # Print the attributes of the base clip\n",
    "    print(\"Base Clip Attributes:\", dir(base_clip))\n",
    "\n",
    "    # Set the duration of the base clip to the number of steps\n",
    "    base_duration = (num_steps / fps)*.05\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    # Print the updated duration of the base clip\n",
    "    print(\"Base Clip Duration (Updated):\", base_clip.duration)\n",
    "\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1 / num_steps\n",
    "    #step_size = .25 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(1,num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        print(i)\n",
    "        if i ==0:\n",
    "            size = (1, 1)\n",
    "        else:\n",
    "            Size = (int(width * (1.0 + i * step_size))/num_steps, int(height * (1.0 + i * step_size))/num_steps)\n",
    "            print(Size)\n",
    "        size = (i*10),(i*10)\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n",
    "\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa02db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "\n",
    "    # Print the attributes of the base clip\n",
    "    print(\"Base Clip Attributes:\", dir(base_clip))\n",
    "\n",
    "    # Set the duration of the base clip to the number of steps\n",
    "    base_duration = (num_steps / fps)*.05\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    # Print the updated duration of the base clip\n",
    "    print(\"Base Clip Duration (Updated):\", base_clip.duration)\n",
    "\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"zooms/output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a new transparent image with increased size for each iteration\n",
    "        new_size = (int(w + w * inc), int(h + h * inc))\n",
    "        final_image = Image.new(\"RGBA\", new_size, (0, 0, 0, 0))\n",
    "\n",
    "        # Calculate the top-left coordinates to center the original image on the final image\n",
    "        x_offset = (new_size[0] - w) // 2\n",
    "        y_offset = (new_size[1] - h) // 2\n",
    "\n",
    "        # Paste the original image onto the final image at the calculated coordinates\n",
    "        final_image.paste(original_image, (x_offset, y_offset))\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the final image\n",
    "        x_overlay_offset = (new_size[0] - resized_original.width) // 2\n",
    "        y_overlay_offset = (new_size[1] - resized_original.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay_image = Image.new(\"RGBA\", new_size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the resized overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay_image.paste(resized_original, (x_overlay_offset, y_overlay_offset))\n",
    "\n",
    "        # Set the opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Composite the overlay image with the final image\n",
    "        final_image = Image.alpha_composite(final_image, overlay_image)\n",
    "        DIR = \"zooms/\"\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{DIR}{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "num_images = 4  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d72407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/jack/hidden/MUSIC.py\n",
    "import glob\n",
    "import random\n",
    "def music():\n",
    "    MUSIC = random.choice(glob.glob(\"/home/jack/Desktop/HDD500/collections/Music/*.mp3\"))\n",
    "    return MUSIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a01ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "import random\n",
    "import glob\n",
    "import uuid\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    bg = bg.resize((768,512), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((bg.size), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(100):\n",
    "        size = (int(fg_copy.width * (i+1)/100), int(fg_copy.height * (i+1)/100))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/100))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/100))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "    # Save the resulting images as a GIF animation\n",
    "    unique_filename = str(uuid.uuid4())+\".gif\"\n",
    "    result_images[0].save('static/images/steampunk/NewFolder/'+unique_filename, save_all=True, append_images=result_images[1:], optimize=False, duration=100, loop=0)\n",
    "#zoom_effect(bg_file, fg_file)\n",
    "for i in range(0,50):\n",
    "    bg_file = random.choice(glob.glob(\"static/images/steampunk/NewFolder/*.jpg\"))\n",
    "    fg_file = random.choice(glob.glob(\"static/images/steampunk/NewFolder/*.jpg\"))\n",
    "\n",
    "    zoom_effect(bg_file, fg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbae3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static/images/steampunk/NewFolder/zoom_effect.gif\r\n"
     ]
    }
   ],
   "source": [
    "!ls static/images/steampunk/NewFolder/zoom_effect.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887aef7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloned-base",
   "language": "python",
   "name": "cloned-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
