{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfc7666",
   "metadata": {},
   "source": [
    "# Video Warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob \n",
    "import random\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "def motionvid():\n",
    "    #filename = random.choice(glob.glob(\"*.jpg\"))\n",
    "    #basedir=\"/home/jack/Desktop/HDD500/collections/newdownloads/mine-new/\"\n",
    "    basedir=\"/home/jack/Desktop/StoryMaker/static/goddess/\"\n",
    "    filename = random.choice(glob.glob(basedir+\"*.jpg\"))\n",
    "    im = Image.open(filename).convert(\"RGB\")\n",
    "    im = im.resize((640,640),Image.BICUBIC)\n",
    "    im.save(\"TEMPimg.jpg\")\n",
    "    # Read the image\n",
    "    img = cv2.imread(\"TEMPimg.jpg\")\n",
    "    \n",
    "\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixel_values = img.reshape((-1, 3))\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    #pixel_values = img.reshape((-1, 3))\n",
    "\n",
    "    # Convert pixel values to float\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "\n",
    "    # Define the number of clusters (colors) to use\n",
    "    k = 26\n",
    "\n",
    "    # Define criteria and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Convert the centers back to uint8 and reshape the labels back to the original image shape\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "\n",
    "    # Apply the wave effect to the image\n",
    "    h, w = img.shape[:2]\n",
    "    wave_x = 2 * w\n",
    "    wave_y = h\n",
    "    amount_x = 10\n",
    "    amount_y = 5\n",
    "    num_frames = 300\n",
    "    delay = 50\n",
    "    border_color = (0, 0, 0)\n",
    "    x = np.arange(w, dtype=np.float32)\n",
    "    y = np.arange(h, dtype=np.float32)\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        phase_x = i * 360 / num_frames\n",
    "        phase_y = phase_x\n",
    "        x_sin = amount_x * np.sin(2 * np.pi * (x / wave_x + phase_x / 360)) + x\n",
    "        map_x = np.tile(x_sin, (h, 1))\n",
    "        y_sin = amount_y * np.sin(2 * np.pi * (y / wave_y + phase_y / 360)) + y\n",
    "        map_y = np.tile(y_sin, (w, 1)).transpose()\n",
    "        result = cv2.remap(img.copy(), map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=border_color)\n",
    "        frames.append(result)\n",
    "\n",
    "    # Save the frames as an MP4 video file\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    now = datetime.datetime.now()\n",
    "    #vidname = \"newvid/\"+now.strftime(\"%Y-%m-%d_%H-%M-%S-%f\")[:-3] + \"new.mp4\"\n",
    "    vidname = \"newvid/text.mp4\"\n",
    "    print(vidname)\n",
    "    out = cv2.VideoWriter(vidname, fourcc, 25.0, (w, h))\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6478031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob \n",
    "import random\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "def motionvid():\n",
    "    #filename = random.choice(glob.glob(\"*.jpg\"))\n",
    "    #basedir=\"/home/jack/Desktop/HDD500/collections/newdownloads/mine-new/\"\n",
    "    #basedir=\"/home/jack/Desktop/StoryMaker/static/goddess/\"\n",
    "    basedir=\"/home/jack/Desktop/StoryMaker/static/goddess/ai-generations_files/\"\n",
    "    filename = random.choice(glob.glob(basedir+\"*.jpg\"))\n",
    "    im = Image.open(filename).convert(\"RGB\")\n",
    "    im = im.resize((512,768),Image.BICUBIC)\n",
    "    im.save(\"TEMPimg.jpg\")\n",
    "    # Read the image\n",
    "    img = cv2.imread(\"TEMPimg.jpg\")\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixel_values = img.reshape((-1, 3))\n",
    "    # Convert pixel values to float\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "    # Define the number of clusters (colors) to use\n",
    "    k = 26\n",
    "    # Define criteria and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Convert the centers back to uint8 and reshape the labels back to the original image shape\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "\n",
    "    # Apply the wave effect to the image\n",
    "    h, w = img.shape[:2]\n",
    "    #wave_x = 2 * w\n",
    "    wave_x = 3 * w\n",
    "    wave_y = h\n",
    "    #amount_x = 10\n",
    "    #amount_y = 5\n",
    "    amount_x = 65\n",
    "    amount_y = 75\n",
    "    num_frames = 1000\n",
    "    delay = 1\n",
    "    border_color = (0, 0, 0)\n",
    "    x = np.arange(w, dtype=np.float32)\n",
    "    y = np.arange(h, dtype=np.float32)\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        phase_x = i * 360 / num_frames\n",
    "        phase_y = phase_x\n",
    "        x_sin = amount_x * np.sin(2 * np.pi * (x / wave_x + phase_x / 360)) + x\n",
    "        map_x = np.tile(x_sin, (h, 1))\n",
    "        y_sin = amount_y * np.sin(2 * np.pi * (y / wave_y + phase_y / 360)) + y\n",
    "        map_y = np.tile(y_sin, (w, 1)).transpose()\n",
    "        result = cv2.remap(img.copy(), map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=border_color)\n",
    "        frames.append(result)\n",
    "\n",
    "    # Save the frames as an MP4 video file\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    now = datetime.datetime.now()\n",
    "    #vidname = \"newvid/\"+now.strftime(\"%Y-%m-%d_%H-%M-%S-%f\")[:-3] + \"new.mp4\"\n",
    "    vidname = \"newvid/text2.mp4\"\n",
    "    print(vidname)\n",
    "    out = cv2.VideoWriter(vidname, fourcc, 25.0, (w, h))\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e058333",
   "metadata": {},
   "outputs": [],
   "source": [
    "motionvid()\n",
    "!vlc newvid/text2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29954bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607842a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc newvid/text.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7ff52",
   "metadata": {},
   "source": [
    "# Good working with fade transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76458216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good working with fade transition\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),30)\n",
    "\n",
    "# Define the transitions\n",
    "def crossfade(clip1, clip2):\n",
    "    return CompositeVideoClip([clip1.fx(vfx.fadeout, duration=1), \n",
    "                               clip2.fx(vfx.fadein, duration=1)], \n",
    "                              size=size)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a crossfade transition to the previous clip\n",
    "        transition = crossfade(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshowT.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5dac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip\n",
    "\n",
    "def add_title_image(video_path, title_image_path, output_path):\n",
    "    # Load the video file and title image\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    title_image = ImageClip(title_image_path)\n",
    "\n",
    "    # Set the duration of the title image\n",
    "    title_duration = video_clip.duration\n",
    "    title_image = title_image.set_duration(title_duration)\n",
    "\n",
    "    # Position the title image at the center and resize it to fit the video dimensions\n",
    "    title_image = title_image.set_position((\"center\", \"center\"))\n",
    "    title_image = title_image.resize(video_clip.size)\n",
    "\n",
    "    # Create a composite video clip with the title image overlay\n",
    "    composite_clip = CompositeVideoClip([video_clip, title_image])\n",
    "\n",
    "    # Set the audio of the composite clip to the original video's audio\n",
    "    composite_clip = composite_clip.set_audio(video_clip.audio)\n",
    "\n",
    "    # Export the final video with the title image\n",
    "    composite_clip.write_videofile(output_path)\n",
    "\n",
    "# Example usage\n",
    "video_path = \"static/alice/Final_End.mp4\"\n",
    "title_image_path = \"static/current_project/Images/Title_Image.png\"\n",
    "output_path = \"static/alice/Titled_Final_End.mp4\"\n",
    "\n",
    "add_title_image(video_path, title_image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f552d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/jack/Downloads/saved_pages/mine-new/0001_Shot.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/Zulko/moviepy\n",
    "https://github.com/fujiawei-dev/ffmpeg-generator \n",
    "https://gfycat.com/create\n",
    "https://man.archlinux.org/man/ffmpeg-filters.1.en\n",
    "https://trac.ffmpeg.org/wiki/Capture/ALSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.mltframework.org/\n",
    "https://ffmpeg.org/ffmpeg-filters.html#concat\n",
    "https://github.com/mltframework/mlt/releases\n",
    "https://copyprogramming.com/howto/nlmeans-ffmpeg-is-it-really-so-slow\n",
    "https://snyk.io/advisor/npm-package/fluent-ffmpeg/functions/fluent-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /home/jack/Downloads/saved_pages/mine-new/Title.png ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ab21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "TITLE = random.choice([\"Title.jpg\",\"Title.png\",\"title.jpg\"])\n",
    "TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca230f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips, ImageClip, vfx\n",
    "\n",
    "# Set the duration of the transition in seconds\n",
    "transition_duration = 2\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('animated.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 15)\n",
    "\n",
    "# Load the title image as an ImageClip object and set its duration\n",
    "TITLE = random.choice([\"Title.jpg\",\"Title.png\",\"title.jpg\"])\n",
    "title_image = ImageClip(TITLE).set_duration(2)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object and add a transition\n",
    "clips = [title_image]\n",
    "for i, file in enumerate(selected_files):\n",
    "    clip = VideoFileClip(file)\n",
    "    if i > 0:\n",
    "        transition_duration = min(transition_duration, clip.duration)\n",
    "        transition = CompositeVideoClip([clips[-1].set_end(clips[-1].duration-transition_duration),\n",
    "                                         clip.set_start(transition_duration)])\n",
    "        clips.append(transition)\n",
    "    clips.append(clip)\n",
    "\n",
    "# Concatenate the clips into one video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"animated-joined_02a.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "# Set the duration of the transition in seconds\n",
    "transition_duration = 2\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('animated.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 6)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object and add a transition\n",
    "clips = []\n",
    "for i, file in enumerate(selected_files):\n",
    "    clip = VideoFileClip(file)\n",
    "    if i > 0:\n",
    "        transition_duration = min(transition_duration, clip.duration)\n",
    "        transition = CompositeVideoClip([clips[-1].set_end(clips[-1].duration-transition_duration),\n",
    "                                         clip.set_start(transition_duration)])\n",
    "        clips.append(transition)\n",
    "    clips.append(clip)\n",
    "\n",
    "# Concatenate the clips into one video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"animation_out_A.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f6dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Replace 'myvideo.mp4' with the path to your own video file\n",
    "#video_path = \"/mnt/HDD500/collections/square_videos/2023-04-03_20-47-11_output.mp4\"\n",
    "video_path = \"shortsoutput01.mp4\"\n",
    "# Read the video file and encode it as base64\n",
    "video_data = open(video_path, 'rb').read()\n",
    "base64_data = b64encode(video_data).decode('ascii')\n",
    "\n",
    "# Embed the video in an HTML5 video element\n",
    "video_html = f\"\"\"\n",
    "<video width=\"400\" height=\"400\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{base64_data}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML object in the notebook\n",
    "HTML(video_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidpy import Clip, Composition\n",
    "from vidpy import Clip, Composition\n",
    "\n",
    "#clip1 = Clip('animated2.mp4', offset=1.5)# start playing clip one after 1.5 seconds\n",
    "#clip2 = Clip('animated.mp4')\n",
    "#clip2.set_offset(5) # start clip2 after 5 seconds\n",
    "\n",
    "#clip1 = Clip('0030short.mp4')\n",
    "#clip2 = Clip('0046short.mp4')\n",
    "\n",
    "clip1 = Clip('0030short.mp4')\n",
    "clip2 = Clip('0046short.mp4', offset=3)\n",
    "#clip2.set_offset(65)\n",
    "# play videos on top of each other\n",
    "composition = Composition([clip1, clip2])\n",
    "composition.save('compose01.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Replace 'myvideo.mp4' with the path to your own video file\n",
    "#video_path = \"/mnt/HDD500/collections/square_videos/2023-04-03_20-47-11_output.mp4\"\n",
    "video_path = \"compose01.mp4\"\n",
    "# Read the video file and encode it as base64\n",
    "video_data = open(video_path, 'rb').read()\n",
    "base64_data = b64encode(video_data).decode('ascii')\n",
    "\n",
    "# Embed the video in an HTML5 video element\n",
    "video_html = f\"\"\"\n",
    "<video width=\"400\" height=\"400\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{base64_data}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML object in the notebook\n",
    "HTML(video_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11816e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca633e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc newvid/2023-07-15_19-56-27-193new.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f02e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,50):\n",
    "    motionvid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acfe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls newvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# Get a list of all the MP4 files in the junk directory\n",
    "file_list = glob.glob(\"newvid/*new.mp4\")\n",
    "\n",
    "# Choose 20 random files from the file list\n",
    "selected_files = random.sample(file_list, 15)\n",
    "\n",
    "# Create a list of VideoFileClip objects from the selected files\n",
    "clip_list = [VideoFileClip(filename) for filename in selected_files]\n",
    "\n",
    "# Concatenate the video clips together into a single clip\n",
    "final_clip = concatenate_videoclips(clip_list)\n",
    "\n",
    "# Write the final clip to a file named JOINED.mp4\n",
    "final_clip.write_videofile(\"newvid/start.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jack/Desktop/HDD500/collections/newdownloads/mine-new/junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir=\"/home/jack/Desktop/HDD500/collections/newdownloads/mine-new/\"\n",
    "filename = random.choice(glob.glob(basedir+\"junk/*__.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -i input.lowfps.hevc -filter \"minterpolate='fps=120'\" output.120fps.hevc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "!locate *.mp4 |grep collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i /mnt/HDD500/collections/square_videos/2023-04-03_20-47-11_output.mp4 \\\n",
    "-filter:v \"minterpolate='fps=120'\" -y output.120fps.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d00a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command as a list of strings\n",
    "command = ['ffmpeg', '-y', '-r', '0.3', '-stream_loop', '1', '-i', '2023-04-13-10-15-59.jpg', '-r', '0.3', '-stream_loop', '2', '-i', '2023-04-13-15-21-31.jpg', '-filter_complex', '[0][1]concat=n=2:v=1:a=0[v];[v]minterpolate=fps=24:scd=none,trim=3:7,setpts=PTS-STARTPTS', '-pix_fmt', 'yuv420p', '-y','test02.mp4']\n",
    "\n",
    "# Run the command using subprocess.Popen\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Get the output and error messages (if any)\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Print the output and error messages\n",
    "print(stdout.decode('utf-8'))\n",
    "print(stderr.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -r 0.3 -stream_loop 1 -i 2023-04-13-10-15-59.jpg -r 0.3 -stream_loop 2 -i \\ 2023-04-13-15-21-31.jpg -filter_complex \"[0][1]concat=n=2:v=1:a=0[v]; \\[v]minterpolate=fps=24:scd=none,trim=3:7,setpts=PTS-STARTPTS\" -pix_fmt yuv420p \\ test02.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Replace 'myvideo.mp4' with the path to your own video file\n",
    "#video_path = \"/mnt/HDD500/collections/square_videos/2023-04-03_20-47-11_output.mp4\"\n",
    "video_path = \"output.120fps.mp4\"\n",
    "# Read the video file and encode it as base64\n",
    "video_data = open(video_path, 'rb').read()\n",
    "base64_data = b64encode(video_data).decode('ascii')\n",
    "\n",
    "# Embed the video in an HTML5 video element\n",
    "video_html = f\"\"\"\n",
    "<video width=\"400\" height=\"400\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{base64_data}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML object in the notebook\n",
    "HTML(video_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47deb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Replace 'myvideo.mp4' with the path to your own video file\n",
    "#video_path = \"/mnt/HDD500/collections/square_videos/2023-04-03_20-47-11_output.mp4\"\n",
    "video_path = \"output.120fps.mp4\"\n",
    "# Read the video file and encode it as base64\n",
    "video_data = open(video_path, 'rb').read()\n",
    "base64_data = b64encode(video_data).decode('ascii')\n",
    "\n",
    "# Embed the video in an HTML5 video element\n",
    "video_html = f\"\"\"\n",
    "<video width=\"640\" height=\"640\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{base64_data}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML object in the notebook\n",
    "HTML(video_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Replace 'myvideo.mp4' with the path to your own video file\n",
    "video_path = '/mnt/HDD500/collections/square_videos/2023-04-03_20-47-11_output.mp4'\n",
    "\n",
    "# Embed the video player in an HTML object\n",
    "video_html = f\"\"\"\n",
    "<video width=500 controls>\n",
    "    <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML object in the notebook\n",
    "HTML(video_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -i input.lowfps.hevc -filter \"minterpolate='fps=120'\" output.120fps.hevc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -y -fflags +genpts -r 30 -i $input01 -vf \"setpts=100*PTS,minterpolate=fps=24:scd=none\" -pix_fmt yuv420p \"test01.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "We received your request for an API key from us here at Gfycat.  Please find your credentials below:\n",
    "\n",
    "App name: experimental\n",
    "Client ID: 2_dVjMKA\n",
    "Client Secret: zH2l3rvGIshCSbPLXm8LM15J4vGlUNQlkVe9uRzwfhAnUDjTkCDf9gA9qJysRDIw\n",
    "\n",
    "Some cool capabilities of the API include:\n",
    "\n",
    "    • Pulling in trending GIFs and categories of GIFs\n",
    "    • Pulling in GIFs via search from Gfycat\n",
    "    • Allowing you or your users to upload and create GIFs\n",
    "    • Allowing you or your users to upload or pull GIFs from their or other users’ accounts on Gfycat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1598d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gfycat.client import GfycatClient\n",
    "import requests\n",
    "\n",
    "client_id = \"2_dVjMKA\"\n",
    "client_secret = \"zH2l3rvGIshCSbPLXm8LM15J4vGlUNQlkVe9uRzwfhAnUDjTkCDf9gA9qJysRDIw\"\n",
    "\n",
    "# Construct the API endpoint URL for testing credentials\n",
    "test_url = f\"https://api.gfycat.com/v1/me?client_id={client_id}&client_secret={client_secret}\"\n",
    "\n",
    "# Send a GET request to the test URL\n",
    "response = requests.get(test_url)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    print(\"Credentials are valid!\")\n",
    "else:\n",
    "    print(\"Invalid credentials. Please check your client ID and secret.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gfycat.client import GfycatClient\n",
    "\n",
    "client = GfycatClient(\"2_dVjMKA\",\"zH2l3rvGIshCSbPLXm8LM15J4vGlUNQlkVe9uRzwfhAnUDjTkCDf9gA9qJysRDIw\")\n",
    "\n",
    "# Example request\n",
    "client.upload_from_file('animation.gif')\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "GfycatClientError                         Traceback (most recent call last)\n",
    "Cell In[25], line 6\n",
    "      3 client = GfycatClient(\"2_dVjMKA\",\"zH2l3rvGIshCSbPLXm8LM15J4vGlUNQlkVe9uRzwfhAnUDjTkCDf9gA9qJysRDIw\")\n",
    "      5 # Example request\n",
    "----> 6 client.upload_from_file('animation.gif')\n",
    "\n",
    "File ~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/gfycat/client.py:61, in GfycatClient.upload_from_file(self, filename)\n",
    "     58 r = requests.post(FILE_UPLOAD_ENDPOINT, data=data, files=files)\n",
    "     60 if r.status_code != 200:\n",
    "---> 61     raise GfycatClientError('Error uploading the GIF', r.status_code)\n",
    "     63 info = self.uploaded_file_info(key)\n",
    "     64 while 'timeout' in info.get('error', '').lower():\n",
    "\n",
    "GfycatClientError: (403) Error uploading the GIF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d84f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob 1  \n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "#img = cv2.imread(\"/home/jack/Desktop/HDD500/collections/newdownloads/512x512/2023-04-13-11-26-06.jpg\")\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "\n",
    "# Load the image\n",
    "filename = random.choice(glob.glob(\"*.jpg\"))\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# Reshape the image to a 2D array of pixels\n",
    "pixel_values = img.reshape((-1, 3))\n",
    "\n",
    "# Convert pixel values to float\n",
    "pixel_values = np.float32(pixel_values)\n",
    "\n",
    "# Define the number of clusters (colors) to use\n",
    "k = 26\n",
    "\n",
    "# Define criteria and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "_, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Convert the centers back to uint8 and reshape the labels back to the original image shape\n",
    "centers = np.uint8(centers)\n",
    "res = centers[labels.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "img = res2\n",
    "# get dimensions\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# set wavelength\n",
    "wave_x = 2*w\n",
    "wave_y = h\n",
    "\n",
    "# set amount, number of frames and delay\n",
    "amount_x = 10\n",
    "amount_y = 5\n",
    "num_frames = 100\n",
    "delay = 50\n",
    "border_color = (128,128,128)\n",
    "\n",
    "# create X and Y ramps\n",
    "x = np.arange(w, dtype=np.float32)\n",
    "y = np.arange(h, dtype=np.float32)\n",
    "\n",
    "frames = []\n",
    "# loop and change phase\n",
    "for i in range(0,num_frames):\n",
    "\n",
    "    # compute phase to increment over 360 degree for number of frames specified so makes full cycle\n",
    "    phase_x = i*360/num_frames\n",
    "    phase_y = phase_x\n",
    "\n",
    "    # create sinusoids in X and Y, add to ramps and tile out to fill to size of image\n",
    "    x_sin = amount_x * np.sin(2 * np.pi * (x/wave_x + phase_x/360)) + x\n",
    "    map_x = np.tile(x_sin, (h,1))\n",
    "\n",
    "    y_sin = amount_y * np.sin(2 * np.pi * (y/wave_y + phase_y/360)) + y\n",
    "    map_y = np.tile(y_sin, (w,1)).transpose()\n",
    "\n",
    "    # do the warping using remap\n",
    "    result = cv2.remap(img.copy(), map_x, map_y, cv2.INTER_CUBIC, borderMode = cv2.BORDER_CONSTANT, borderValue=border_color)\n",
    "        \n",
    "    # show result\n",
    "    #cv2.imshow('result', result)\n",
    "    #cv2.waitKey(delay)\n",
    "\n",
    "    # convert to PIL format and save frames\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    pil_result = Image.fromarray(result)\n",
    "    frames.append(pil_result)\n",
    "\n",
    "# write animated gif from frames using PIL\n",
    "frames[0].save('animation.gif',save_all=True, append_images=frames[1:], optimize=False, duration=delay, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "img = cv2.imread(\"/home/jack/Desktop/HDD500/collections/newdownloads/512x512/2023-04-13-11-27-05.jpg\")\n",
    "\n",
    "# Reshape the image to a 2D array of pixels\n",
    "pixel_values = img.reshape((-1, 3))\n",
    "\n",
    "# Convert pixel values to float\n",
    "pixel_values = np.float32(pixel_values)\n",
    "\n",
    "# Define the number of clusters (colors) to use\n",
    "k = 26\n",
    "\n",
    "# Define criteria and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "_, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Convert the centers back to uint8 and reshape the labels back to the original image shape\n",
    "centers = np.uint8(centers)\n",
    "res = centers[labels.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "img = res2\n",
    "# get dimensions\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# set wavelength\n",
    "wave_x = 2*w\n",
    "wave_y = h\n",
    "\n",
    "# set amount, number of frames and delay\n",
    "amount_x = 10\n",
    "amount_y = 5\n",
    "num_frames = 100\n",
    "delay = 50\n",
    "border_color = (128,128,128)\n",
    "\n",
    "# create X and Y ramps\n",
    "x = np.arange(w, dtype=np.float32)\n",
    "y = np.arange(h, dtype=np.float32)\n",
    "\n",
    "frames = []\n",
    "# loop and change phase\n",
    "for i in range(0,num_frames):\n",
    "\n",
    "    # compute phase to increment over 360 degree for number of frames specified so makes full cycle\n",
    "    phase_x = i*360/num_frames\n",
    "    phase_y = phase_x\n",
    "\n",
    "    # create sinusoids in X and Y, add to ramps and tile out to fill to size of image\n",
    "    x_sin = amount_x * np.sin(2 * np.pi * (x/wave_x + phase_x/360)) + x\n",
    "    map_x = np.tile(x_sin, (h,1))\n",
    "\n",
    "    y_sin = amount_y * np.sin(2 * np.pi * (y/wave_y + phase_y/360)) + y\n",
    "    map_y = np.tile(y_sin, (w,1)).transpose()\n",
    "\n",
    "    # do the warping using remap\n",
    "    result = cv2.remap(img.copy(), map_x, map_y, cv2.INTER_CUBIC, borderMode = cv2.BORDER_CONSTANT, borderValue=border_color)\n",
    "    # convert to PIL format and save frames\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    pil_result = Image.fromarray(result)\n",
    "    frames.append(pil_result)\n",
    "\n",
    "# write animated gif from frames using PIL\n",
    "frames[0].save('animation2.gif',save_all=True, append_images=frames[1:], optimize=False, duration=delay, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob \n",
    "import random\n",
    "import datetime\n",
    "#img = cv2.imread(\"/home/jack/Desktop/HDD500/collections/newdownloads/512x512/2023-04-13-11-26-06.jpg\")\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "\n",
    "# Load the image\n",
    "filename = random.choice(glob.glob(\"*.jpg\"))\n",
    "# Read the image\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# Reshape the image to a 2D array of pixels\n",
    "pixel_values = img.reshape((-1, 3))\n",
    "\n",
    "# Convert pixel values to float\n",
    "pixel_values = np.float32(pixel_values)\n",
    "\n",
    "# Define the number of clusters (colors) to use\n",
    "k = 26\n",
    "\n",
    "# Define criteria and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "_, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Convert the centers back to uint8 and reshape the labels back to the original image shape\n",
    "centers = np.uint8(centers)\n",
    "res = centers[labels.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "# Apply the wave effect to the image\n",
    "h, w = img.shape[:2]\n",
    "wave_x = 2 * w\n",
    "wave_y = h\n",
    "amount_x = 10\n",
    "amount_y = 5\n",
    "num_frames = 100\n",
    "delay = 50\n",
    "border_color = (128, 128, 128)\n",
    "x = np.arange(w, dtype=np.float32)\n",
    "y = np.arange(h, dtype=np.float32)\n",
    "frames = []\n",
    "for i in range(num_frames):\n",
    "    phase_x = i * 360 / num_frames\n",
    "    phase_y = phase_x\n",
    "    x_sin = amount_x * np.sin(2 * np.pi * (x / wave_x + phase_x / 360)) + x\n",
    "    map_x = np.tile(x_sin, (h, 1))\n",
    "    y_sin = amount_y * np.sin(2 * np.pi * (y / wave_y + phase_y / 360)) + y\n",
    "    map_y = np.tile(y_sin, (w, 1)).transpose()\n",
    "    result = cv2.remap(img.copy(), map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=border_color)\n",
    "    frames.append(result)\n",
    "\n",
    "# Save the frames as an MP4 video file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "now = datetime.datetime.now()\n",
    "vidname = now.strftime(\"%Y-%m-%d_%H-%M-%S-%f\")[:-3] + \".mp4\"\n",
    "out = cv2.VideoWriter(vidname, fourcc, 25.0, (w, h))\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f4ff7",
   "metadata": {},
   "source": [
    "# 17.9.1 Examples\n",
    "<p>Concatenate an opening, an episode and an ending, all in bilingual version (video in stream 0, audio in streams 1 and 2):</p><br />\n",
    "<code>\n",
    "ffmpeg -i opening.mkv -i episode.mkv -i ending.mkv -filter_complex \\<br />\n",
    "  '[0:0] [0:1] [0:2] [1:0] [1:1] [1:2] [2:0] [2:1] [2:2]<br />\n",
    "   concat=n=3:v=1:a=2 [v] [a1] [a2]' \\<br />\n",
    "  -map '[v]' -map '[a1]' -map '[a2]' output.mkv<br />\n",
    "</code>\n",
    "<p> Concatenate two parts, handling audio and video separately,<br />\n",
    "using the (a)movie sources, and adjusting the resolution:<br />\n",
    "movie=part1.mp4, scale=512:288 [v1] ; amovie=part1.mp4 [a1] ;<br />\n",
    "movie=part2.mp4, scale=512:288 [v2] ; amovie=part2.mp4 [a2] ;<br />\n",
    "[v1] [v2] concat [outv] ; [a1] [a2] concat=v=0:a=1 [outa]<br />\n",
    "Note that a desync will happen at the stitch if the audio and <br />\n",
    "video streams do not have exactly the same duration in the first file.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidpy import config\n",
    "config.MELT_BINARY = '/path/to/melt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd81118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidpy import Clip, Composition\n",
    "# start playing clip one after 1.5 seconds\n",
    "clip1 = Clip('animated2.mp4', offset=1.5)\n",
    "\n",
    "clip2 = Clip('animated.mp4')\n",
    "clip2.set_offset(5) # start clip2 after 5 seconds\n",
    "\n",
    "composition = Composition([clip1, clip2])\n",
    "composition.save('output2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44034a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmpeg import _filters\n",
    "print(_filters.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmpeg import _filters\n",
    "help(_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ad69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "help(ffmpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ccbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "help(ffmpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "dir(ffmpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ffmpeg import constants, FFprobe, input, settings\n",
    "from tests import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5604733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmpeg import zoompan\n",
    "help(zoompan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435582c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmpeg import input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0848e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "input_file = '/home/jack/Desktop/HDD500/to-vid/building/01145.jpg'\n",
    "output_file = 'test.mp4'\n",
    "zoompan_filter = 'zoompan=z=\\'min(zoom+0.0015,1.5)\\':d=700:x=\\'if(gte(zoom,1.5),x,x+1/a)\\':y=\\'if(gte(zoom,1.5),y,y+1)\\':s=640x640'\n",
    "\n",
    "(\n",
    "    ffmpeg\n",
    "    .input(input_file, loop=1)\n",
    "    .filter(zoompan_filter, duration=10)\n",
    "    .output(output_file, vcodec='libx264', pix_fmt='yuv420p')\n",
    "    .run()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works Good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i /home/jack/Desktop/HDD500/collections/newdownloads/mine-new/newvid/2023-04-20_00-06-43-983new.mp4 -vf \"zoompan=z='min(max(zoom,pzoom)+0.0025,1.5)':d=300:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'\" -t 180 -y /home/jack/Desktop/HDD500/collections/newdownloads/mine-new/newvid/test3.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i /home/jack/Desktop/HDD500/to-vid/building/test3.mp4 -vf \"zoompan=z='min(max(zoom,pzoom)+0.0025,1.5)':d=125:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'\" -y /home/jack/Desktop/HDD500/to-vid/building/test2.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i /home/jack/Desktop/HDD500/to-vid/building/test3.mp4 -vf \"zoompan=z='if(between(in_time,0,1),2,1)':d=1:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'\" -y /home/jack/Desktop/HDD500/to-vid/building/test2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir steampunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works Good \n",
    "!ffmpeg -i /home/jack/Desktop/StoryMaker/static/images/steampunk/personal-feed_files/00009.jpg -vf \"zoompan=z='min(zoom+0.0015,1.5)':d=60000:x='if(gte(zoom,1.5),x,x+1/a)':y='if(gte(zoom,1.5),y,y+1)':s=768x512\" -t 180 -y steampunk/test3.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46834099",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc steampunk/test3.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76074912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works Good \n",
    "!ffmpeg -i /home/jack/Desktop/StoryMaker/static/images/steampunk/personal-feed_files/00009.jpg -vf \"zoompan=z='min(zoom+0.0015,1.5)':d=700:x='if(gte(zoom,1.5),x,x+1/a)':y='if(gte(zoom,1.5),y,y+1)':s=768x512\" -y steampunk/test4.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works Good \n",
    "!ffmpeg -i /home/jack/Desktop/HDD500/to-vid/building/01145.jpg -vf \"zoompan=z='min(zoom+0.0015,1.5)':d=700:x='if(gte(zoom,1.5),x,x+1/a)':y='if(gte(zoom,1.5),y,y+1)':s=640x640\" -y /home/jack/Desktop/HDD500/to-vid/building/test3.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971efcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "dir(ffmpeg)\n",
    "['Error',\n",
    " 'Stream',\n",
    " '__all__',\n",
    " '__builtins__',\n",
    " '__cached__',\n",
    " '__doc__',\n",
    " '__file__',\n",
    " '__loader__',\n",
    " '__name__',\n",
    " '__package__',\n",
    " '__path__',\n",
    " '__spec__',\n",
    " '_ffmpeg',\n",
    " '_filters',\n",
    " '_probe',\n",
    " '_run',\n",
    " '_utils',\n",
    " '_view',\n",
    " 'colorchannelmixer',\n",
    " 'compile',\n",
    " 'concat',\n",
    " 'crop',\n",
    " 'dag',\n",
    " 'drawbox',\n",
    " 'drawtext',\n",
    " 'filter',\n",
    " 'filter_',\n",
    " 'filter_multi_output',\n",
    " 'get_args',\n",
    " 'hflip',\n",
    " 'hue',\n",
    " 'input',\n",
    " 'merge_outputs',\n",
    " 'nodes',\n",
    " 'output',\n",
    " 'overlay',\n",
    " 'overwrite_output',\n",
    " 'probe',\n",
    " 'run',\n",
    " 'run_async',\n",
    " 'setpts',\n",
    " 'trim',\n",
    " 'unicode_literals',\n",
    " 'vflip',\n",
    " 'view',\n",
    " 'zoompan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ffmpeg import constants, FFprobe, input, settings\n",
    "from tests import data\n",
    "\n",
    "settings.CUDA_ENABLE = False\n",
    "\n",
    "\n",
    "def ffmpeg_input_process(src):\n",
    "    return input(src).output(constants.PIPE, format=\"rawvideo\",\n",
    "                             pixel_format=\"rgb24\").run_async(pipe_stdout=True)\n",
    "\n",
    "\n",
    "def ffmpeg_output_process(dst, width, height):\n",
    "    return input(constants.PIPE, format=\"rawvideo\", pixel_format=\"rgb24\",\n",
    "                 width=width, height=height).output(dst, pixel_format=\"yuv420p\"). \\\n",
    "        run_async(pipe_stdin=True)\n",
    "\n",
    "\n",
    "def read_frame_from_stdout(process: subprocess.Popen, width, height):\n",
    "    frame_size = width * height * 3\n",
    "    input_bytes = process.stdout.read(frame_size)\n",
    "\n",
    "    if not input_bytes:\n",
    "        return\n",
    "\n",
    "    assert len(input_bytes) == frame_size\n",
    "\n",
    "    return np.frombuffer(input_bytes, np.uint8).reshape([height, width, 3])\n",
    "\n",
    "\n",
    "def process_frame_simple(frame):\n",
    "    # deep dream\n",
    "    return frame * 0.3\n",
    "\n",
    "\n",
    "def write_frame_to_stdin(process: subprocess.Popen, frame):\n",
    "    process.stdin.write(frame.astype(np.uint8).tobytes())\n",
    "\n",
    "\n",
    "def run(src, dst, process_frame):\n",
    "    width, height = FFprobe(src).video_scale\n",
    "\n",
    "    input_process = ffmpeg_input_process(src)\n",
    "    output_process = ffmpeg_output_process(dst, width, height)\n",
    "\n",
    "    while True:\n",
    "        input_frame = read_frame_from_stdout(input_process, width, height)\n",
    "\n",
    "        if input_frame is None:\n",
    "            break\n",
    "\n",
    "        write_frame_to_stdin(output_process, process_frame(input_frame))\n",
    "\n",
    "    input_process.wait()\n",
    "\n",
    "    output_process.stdin.close()\n",
    "    output_process.wait()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run(\"slideshow.mp4\", \"processed_slideshow.mp4\", process_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls process_frame.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9059862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 12)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object\n",
    "clips = [VideoFileClip(f) for f in selected_files]\n",
    "\n",
    "# Concatenate the clips into one video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"12output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02804849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "# Set the duration of the transition in seconds\n",
    "transition_duration = 1\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 15)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object and add a transition\n",
    "clips = []\n",
    "for i, file in enumerate(selected_files):\n",
    "    clip = VideoFileClip(file)\n",
    "    if i > 0:\n",
    "        transition = CompositeVideoClip([clips[-1].set_end(clips[-1].duration-transition_duration),\n",
    "                                         clip.set_start(transition_duration)],\n",
    "                                        duration=transition_duration)\n",
    "        clips.append(transition)\n",
    "    clips.append(clip)\n",
    "\n",
    "# Concatenate the clips into one video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"15trans_output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "# Set the duration of the transition in seconds\n",
    "transition_duration = 1\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 14)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object and add a transition\n",
    "clips = []\n",
    "for i, file in enumerate(selected_files):\n",
    "    clip = VideoFileClip(file)\n",
    "    if i > 0:\n",
    "        transition_duration = min(transition_duration, clip.duration)\n",
    "        transition = CompositeVideoClip([clips[-1].set_end(clips[-1].duration-transition_duration),clip.set_start(transition_duration)])\n",
    "        clips.append(transition)\n",
    "        clips.append(clip)\n",
    "\n",
    "# Concatenate the clips into one video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"15output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, CompositeVideoClip\n",
    "\n",
    "# Set the duration of the cross-fade transition in seconds\n",
    "transition_duration = 2\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('animated.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 8)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object and add a transition\n",
    "clips = []\n",
    "for i, file in enumerate(selected_files):\n",
    "    clip = VideoFileClip(file)\n",
    "    if i > 0:\n",
    "        # Determine the duration of the transition\n",
    "        transition_duration = min(transition_duration, clip.duration, clips[i-1].duration)\n",
    "        # Create a cross-fade transition\n",
    "        transition = CompositeVideoClip([clips[i-1].set_end(clips[i-1].duration-transition_duration),\n",
    "                                         clip.set_start(transition_duration)])\n",
    "        clips.append(transition)\n",
    "    clips.append(clip)\n",
    "\n",
    "# Concatenate the clips into one video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"blend-shorts-8-output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "# Set the duration of the cross-fade transition in seconds\n",
    "transition_duration = 2\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('animated.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 8)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object\n",
    "clips = [VideoFileClip(file) for file in selected_files]\n",
    "\n",
    "# Add cross-fade transitions between the clips\n",
    "transitions = [None] * (len(clips) - 1)\n",
    "for i in range(len(transitions)):\n",
    "    transition_out = clips[i].crossfadeout(transition_duration)\n",
    "    transition_in = clips[i+1].crossfadein(transition_duration)\n",
    "    transition = CompositeVideoClip([transition_out, transition_in])\n",
    "    transitions[i] = transition\n",
    "\n",
    "# Concatenate the clips and transitions into one video\n",
    "final_clip = concatenate_videoclips([clips[0]] + transitions + clips[1:])\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(\"test-output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips\n",
    "\n",
    "# Set the directory path to search for images\n",
    "directory = os.getcwd()\n",
    "directory = \"/home/jack/Downloads/saved_pages/mine-new\"\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "# Filter the images by size\n",
    "filtered_images = []\n",
    "for file_path in image_files:\n",
    "    with Image.open(file_path) as img:\n",
    "        if img.size == (512, 1024):\n",
    "            filtered_images.append(file_path)\n",
    "\n",
    "# Print the list of filtered images\n",
    "#print(random.sample(filtered_images,20))\n",
    "\n",
    "# Sort the filtered images alphabetically\n",
    "filtered_images =random.sample(filtered_images,30)\n",
    "\n",
    "# Sort the filtered images alphabetically\n",
    "print(len(filtered_images))\n",
    "\n",
    "# Create a list of clips from the images with a crossfade transition\n",
    "clips = []\n",
    "for i in range(len(filtered_images)-1):\n",
    "    clip1 = ImageClip(filtered_images[i], duration=1)\n",
    "    clip2 = ImageClip(filtered_images[i+1], duration=1)\n",
    "    cross_fade = clip2.crossfadein(1)\n",
    "    clips.append(clip1.crossfadeout(1).set_duration(2) )\n",
    "    clips.append(cross_fade.set_duration(2))\n",
    "\n",
    "# Concatenate the clips into a single video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(directory+\"/splatteroutput.mp4\", fps=24, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, CompositeVideoClip\n",
    "\n",
    "# Set the directory path to search for images\n",
    "directory = os.getcwd()\n",
    "directory = \"/home/jack/Downloads/saved_pages/mine-new\"\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "# Filter the images by size\n",
    "filtered_images = []\n",
    "for file_path in image_files:\n",
    "    with Image.open(file_path) as img:\n",
    "        if img.size == (512, 1024):\n",
    "            filtered_images.append(file_path)\n",
    "\n",
    "# Sort the filtered images alphabetically\n",
    "filtered_images.sort()\n",
    "\n",
    "# Randomly select 30 images from the filtered list\n",
    "selected_images = random.sample(filtered_images, 30)\n",
    "\n",
    "# Create a list of clips from the images with a crossfade transition\n",
    "clips = []\n",
    "for i in range(len(selected_images)-1):\n",
    "    clip1 = ImageClip(selected_images[i], duration=1)\n",
    "    clip2 = ImageClip(selected_images[i+1], duration=1)\n",
    "    cross_fade = CompositeVideoClip([clip1, clip2.set_start(1).crossfadein(1)])\n",
    "    clips.append(cross_fade.set_duration(2))\n",
    "\n",
    "# Concatenate the clips into a single video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(directory+\"/longsplatteroutput2.mp4\", fps=24, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips\n",
    "\n",
    "# Set the directory path to search for images\n",
    "directory = os.getcwd()\n",
    "directory = \"/home/jack/Downloads/saved_pages/mine-new\"\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "# Filter the images by size\n",
    "filtered_images = []\n",
    "for file_path in image_files:\n",
    "    with Image.open(file_path) as img:\n",
    "        if img.size == (512, 1024):\n",
    "            filtered_images.append(file_path)\n",
    "\n",
    "# Sort the filtered images alphabetically\n",
    "filtered_images.sort()\n",
    "\n",
    "# Randomly select 30 images from the filtered list\n",
    "selected_images = random.sample(filtered_images, 30)\n",
    "\n",
    "# Create a list of clips from the images with a crossfade transition\n",
    "clips = []\n",
    "for i in range(len(selected_images)-1):\n",
    "    clip1 = ImageClip(selected_images[i], duration=1)\n",
    "    clip2 = ImageClip(selected_images[i+1], duration=1)\n",
    "    cross_fade = clip2.crossfadein(1)\n",
    "    clips.append(clip1.crossfadeout(1).set_duration(2) )\n",
    "    clips.append(cross_fade.set_duration(2))\n",
    "\n",
    "# Concatenate the clips into a single video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(directory+\"/longsplatteroutput3.mp4\", fps=24, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Video Slideshow no Effects\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips\n",
    "\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "# Set the directory path to search for images\n",
    "directory = os.getcwd()\n",
    "directory = \"/home/jack/Downloads/saved_pages/mine-new\"\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png') or f.endswith('Shot.jpg')]\n",
    "\n",
    "# Filter the images by size\n",
    "filtered_images = []\n",
    "for file_path in image_files:\n",
    "    with Image.open(file_path) as img:\n",
    "        if img.size == (512, 1024):\n",
    "            filtered_images.append(file_path)\n",
    "\n",
    "# Print the list of filtered images\n",
    "#print(random.sample(filtered_images,20))\n",
    "\n",
    "# Sort the filtered images alphabetically\n",
    "filtered_images =random.sample(filtered_images,30)\n",
    "\n",
    "# Create a list of clips from the images with a crossfade transition\n",
    "clips = []\n",
    "for i in range(len(filtered_images)-1):\n",
    "    clip1 = ImageClip(filtered_images[i], duration=1)\n",
    "    clip2 = ImageClip(filtered_images[i+1], duration=1)\n",
    "    cross_fade = clip2.crossfadein(1)\n",
    "    clips.append(clip1.crossfadeout(1).set_duration(1) )\n",
    "    clips.append(cross_fade.set_duration(1))\n",
    "\n",
    "# Concatenate the clips into a single video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "# Write the final video to a file\n",
    "final_clip.write_videofile(directory+\"/Shot01.mp4\", fps=24, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5182271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "# Set the duration of the cross-fade transition in seconds\n",
    "transition_duration = 1\n",
    "\n",
    "# Set the duration of the title image in seconds\n",
    "title_duration = 2\n",
    "\n",
    "# Load the title image as an ImageClip object\n",
    "title_image = ImageClip(\"Title.jpg\", duration=title_duration)\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('animated.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 7)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object\n",
    "clips = [VideoFileClip(file) for file in selected_files]\n",
    "\n",
    "# Add cross-fade transitions between the clips\n",
    "transitions = [None] * (len(clips) - 1)\n",
    "for i in range(len(transitions)):\n",
    "    transition_out = clips[i].crossfadeout(transition_duration)\n",
    "    transition_in = clips[i+1].crossfadein(transition_duration)\n",
    "    transition = CompositeVideoClip([transition_out, transition_in])\n",
    "    transitions[i] = transition\n",
    "\n",
    "# Concatenate the title image and the final video\n",
    "title_video = concatenate_videoclips([title_image])\n",
    "final_video = concatenate_videoclips([title_video, clips[0]] + transitions + clips[1:])\n",
    "\n",
    "# Write the final video to a file\n",
    "final_video.write_videofile(\"test-output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e620a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKS GREAT\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "# Set the duration of the cross-fade transition in seconds\n",
    "transition_duration = 1\n",
    "\n",
    "# Set the duration of the title image in seconds\n",
    "title_duration = 2\n",
    "\n",
    "# Load the title image as an ImageClip object\n",
    "title_image = ImageClip('title.jpg', duration=title_duration)\n",
    "\n",
    "# Get a list of all the .mp4 files in the current directory\n",
    "mp4_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith('hot.mp4')]\n",
    "\n",
    "# Choose 10 random files from the list\n",
    "selected_files = random.sample(mp4_files, 6)\n",
    "\n",
    "# Load each selected file as a VideoFileClip object\n",
    "clips = [VideoFileClip(file) for file in selected_files]\n",
    "\n",
    "# Add cross-fade transitions between the clips\n",
    "transitions = [None] * (len(clips) - 1)\n",
    "for i in range(len(transitions)):\n",
    "    transition_out = clips[i].crossfadeout(transition_duration)\n",
    "    transition_in = clips[i+1].crossfadein(transition_duration)\n",
    "    transition = CompositeVideoClip([transition_out, transition_in])\n",
    "    transitions[i] = transition\n",
    "\n",
    "# Calculate the transition for the last two clips separately\n",
    "last_transition_out = clips[-2].crossfadeout(transition_duration)\n",
    "last_transition_in = clips[-1].crossfadein(transition_duration)\n",
    "last_transition = CompositeVideoClip([last_transition_out, last_transition_in])\n",
    "\n",
    "# Concatenate the title image, the clips, and the transitions into one video\n",
    "title_video = concatenate_videoclips([title_image])\n",
    "final_video = concatenate_videoclips([title_video, clips[0]])\n",
    "for i in range(len(transitions)):\n",
    "    final_video = concatenate_videoclips([final_video, transitions[i], clips[i+1]])\n",
    "final_video = concatenate_videoclips([final_video, last_transition, clips[-1]])\n",
    "\n",
    "# Write the final video to a file\n",
    "final_video.write_videofile('Post_to_YouTube.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91577ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "# Load video\n",
    "video = VideoFileClip(\"video.mp4\")\n",
    "\n",
    "# Load sound\n",
    "sound = AudioFileClip(\"sound.mp3\")\n",
    "\n",
    "# Set sound duration to match video duration\n",
    "sound = sound.set_duration(video.duration)\n",
    "\n",
    "# Fade in sound for 1 second and out for 2 seconds\n",
    "sound = sound.fadein(1).fadeout(2)\n",
    "\n",
    "# Combine video and sound\n",
    "video_with_sound = video.set_audio(sound)\n",
    "\n",
    "# Write output video with sound\n",
    "video_with_sound.write_videofile(\"output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../Music/Music_for_Creators.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67787d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import *\n",
    "\n",
    "# Load video \n",
    "video = VideoFileClip(\"animated-no-sound-no-transition.mp4\")\n",
    "\n",
    "# Load sound\n",
    "sound = AudioFileClip(\"../../Music/Music_for_Creators.mp4\")\n",
    "\n",
    "# Get a random start time for the sound between 15 and 25 minutes\n",
    "start_time = random.uniform(900, 1500)\n",
    "\n",
    "# Trim sound to start at the random time\n",
    "sound = sound.subclip(start_time)\n",
    "\n",
    "# Fade in sound for 1 second and out for 2 seconds\n",
    "#sound = sound.fx(afx.fade_in, 1).fx(afx.fade_out, 2)\n",
    "sound = sound.fx(afx.audio_fadein, 1).fx(afx.audio_fadeout, 2)\n",
    "\n",
    "# Set the end time of the sound to match the duration of the video\n",
    "sound = sound.set_end(video.duration)\n",
    "\n",
    "# Add audio to video\n",
    "video = video.set_audio(sound)\n",
    "\n",
    "# Write the output video file\n",
    "video.write_videofile(\"animated-with_sound_and_transition.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef509e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "# Load video \n",
    "video = VideoFileClip(\"animated-no-sound-no-transition.mp4\")\n",
    "\n",
    "# Load sound\n",
    "sound = AudioFileClip(\"../../Music/Music_for_Creators.mp4\")\n",
    "\n",
    "# Get a random start time for the sound between 15 and 25 minutes\n",
    "start_time = random.uniform(900, 1500)\n",
    "\n",
    "# Trim sound to start at the random time\n",
    "sound = sound.subclip(start_time)\n",
    "\n",
    "# Fade in sound for 1 second and out for 2 seconds\n",
    "sound = sound.fadein(1).fadeout(2)\n",
    "\n",
    "# Set the end time of the sound to match the duration of the video\n",
    "sound = sound.set_end(video.duration)\n",
    "\n",
    "# Add audio to video\n",
    "video = video.set_audio(sound)\n",
    "\n",
    "# Write the output video file\n",
    "video.write_videofile(\"output.mp4\")\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "Cell In[41], line 17\n",
    "     14 sound = sound.subclip(start_time)\n",
    "     16 # Fade in sound for 1 second and out for 2 seconds\n",
    "---> 17 sound = sound.fadein(1).fadeout(2)\n",
    "     19 # Set the end time of the sound to match the duration of the video\n",
    "     20 sound = sound.set_end(video.duration)\n",
    "\n",
    "AttributeError: 'AudioFileClip' object has no attribute 'fadein'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import random\n",
    "\n",
    "# Load video and audio files\n",
    "# Load video\n",
    "video = VideoFileClip(\"animated-no-sound-no-transition.mp4\")\n",
    "\n",
    "# Load sound\n",
    "sound = AudioFileClip(\"../../Music/Music_for_Creators.mp4\")\n",
    "\n",
    "# Get a random start time between 15 and 25 minutes into the sound clip\n",
    "start_time = random.uniform(900, 1500)\n",
    "\n",
    "# Trim sound to start at the random time\n",
    "sound = sound.subclip(start_time)\n",
    "\n",
    "# Fade in audio for 1 second and out for 2 seconds\n",
    "sound = sound.audio_fadein(1).audio_fadeout(2)\n",
    "\n",
    "# Add audio to video\n",
    "video = video.set_audio(sound)\n",
    "\n",
    "# Write the output video file\n",
    "video.write_videofile(\"output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af9c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "import random\n",
    "\n",
    "# Load video\n",
    "video = VideoFileClip(\"animated-no-sound-no-transition.mp4\")\n",
    "\n",
    "# Load sound\n",
    "sound = AudioFileClip(\"../../Music/Music_for_Creators.mp4\")\n",
    "\n",
    "# Set sound duration to match video duration\n",
    "sound = sound.set_duration(video.duration)\n",
    "\n",
    "# Get a random start time between 15 and 25 minutes from the beginning of the sound file\n",
    "start_time = random.uniform(900, 1500)\n",
    "\n",
    "# Trim sound to start at the random time\n",
    "sound = sound.subclip(start_time)\n",
    "\n",
    "# Fade in sound for 1 second and out for 2 seconds\n",
    "sound = sound.fadein(1).fadeout(2)\n",
    "\n",
    "# Combine video and sound\n",
    "video_with_sound = video.set_audio(sound)\n",
    "\n",
    "# Write output video with sound\n",
    "video_with_sound.write_videofile(\"DEMO_for_youtube.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /usr/local/bin/SuperEffect\n",
    "#!/bin/bash\n",
    "\n",
    "# Print instructions for the user\n",
    "echo \"This script will process a video file located in the current directory.\"\n",
    "echo \"Please ensure that the 'start.mp4' file exists in this directory before proceeding.\"\n",
    "echo \"Press ENTER to continue, or CTRL+C to cancel.\"\n",
    "read\n",
    "\n",
    "# Check if start.mp4 exists in the current directory\n",
    "if [ ! -f \"start.mp4\" ]; then\n",
    "  echo \"Error: 'start.mp4' file not found in current directory.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Process the video file\n",
    "ffmpeg -i \"$(pwd)/start.mp4\" -crf 10 -vf 'minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1' ---\"$(pwd)/TEMPP.mp4\"\n",
    "sleep 1000\n",
    "ffmpeg -i \"$(pwd)/TEMPP.mp4\" -vf mpdecimate,setpts=N/FRAME_RATE/TB -map:v 0 -y \"$(pwd)/SUPER_EFFECT_Output.mkv\"\n",
    "\n",
    "# Remove the temporary file\n",
    "rm \"$(pwd)/TEMPP.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2533a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt\n",
    "Usage: melt [options] [producer [name=value]* ]+\n",
    "Options:\n",
    "  -attach filter[:arg] [name=value]*       Attach a filter to the output\n",
    "  -attach-cut filter[:arg] [name=value]*   Attach a filter to a cut\n",
    "  -attach-track filter[:arg] [name=value]* Attach a filter to a track\n",
    "  -attach-clip filter[:arg] [name=value]*  Attach a filter to a producer\n",
    "  -audio-track | -hide-video               Add an audio-only track\n",
    "  -blank frames                            Add blank silence to a track\n",
    "  -consumer id[:arg] [name=value]*         Set the consumer (sink)\n",
    "  -debug                                   Set the logging level to debug\n",
    "  -filter filter[:arg] [name=value]*       Add a filter to the current track\n",
    "  -getc                                    Get keyboard input using getc\n",
    "  -group [name=value]*                     Apply properties repeatedly\n",
    "  -help                                    Show this message\n",
    "  -jack                                    Enable JACK transport synchronization\n",
    "  -join clips                              Join multiple clips into one cut\n",
    "  -mix length                              Add a mix between the last two cuts\n",
    "  -mixer transition                        Add a transition to the mix\n",
    "  -null-track | -hide-track                Add a hidden track\n",
    "  -profile name                            Set the processing settings\n",
    "  -progress                                Display progress along with position\n",
    "  -query                                   List all of the registered services\n",
    "  -query \"consumers\" | \"consumer\"=id       List consumers or show info about one\n",
    "  -query \"filters\" | \"filter\"=id           List filters or show info about one\n",
    "  -query \"producers\" | \"producer\"=id       List producers or show info about one\n",
    "  -query \"transitions\" | \"transition\"=id   List transitions, show info about one\n",
    "  -query \"profiles\" | \"profile\"=id         List profiles, show info about one\n",
    "  -query \"presets\" | \"preset\"=id           List presets, show info about one\n",
    "  -query \"formats\"                         List audio/video formats\n",
    "  -query \"audio_codecs\"                    List audio codecs\n",
    "  -query \"video_codecs\"                    List video codecs\n",
    "  -remove                                  Remove the most recent cut\n",
    "  -repeat times                            Repeat the last cut\n",
    "  -repository path                         Set the directory of MLT modules\n",
    "  -serialise [filename]                    Write the commands to a text file\n",
    "  -silent                                  Do not display position/transport\n",
    "  -split relative-frame                    Split the last cut into two cuts\n",
    "  -swap                                    Rearrange the last two cuts\n",
    "  -track                                   Add a track\n",
    "  -transition id[:arg] [name=value]*       Add a transition\n",
    "  -verbose                                 Set the logging level to verbose\n",
    "  -timings                                 Set the logging level to timings\n",
    "  -version                                 Show the version and copyright\n",
    "  -video-track | -hide-audio               Add a video-only track\n",
    "For more help: <https://www.mltframework.org/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /usr/local/bin/SuperEffect\n",
    "#!/bin/bash\n",
    "\n",
    "# Print instructions for the user\n",
    "echo \"This script will process a video file located in the current directory.\"\n",
    "echo \"Please ensure that the 'start.mp4' file exists in this directory before proceeding.\"\n",
    "echo \"Press ENTER to continue, or CTRL+C to cancel.\"\n",
    "read\n",
    "\n",
    "# Check if start.mp4 exists in the current directory\n",
    "if [ ! -f \"start.mp4\" ]; then\n",
    "  echo \"Error: 'start.mp4' file not found in current directory.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Process the video file\n",
    "ffmpeg -i \"$(pwd)/start.mp4\" -crf 10 -vf \\ 'minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1' -t 25 \\ \"$(pwd)/TEMPP.mp4\"\n",
    "sleep 1000\n",
    "ffmpeg -i \"$(pwd)/TEMPP.mp4\" -vf mpdecimate,setpts=N/FRAME_RATE/TB -map:v 0 -y \"$(pwd)/SUPER_EFFECT_Output.mkv\"\n",
    "\n",
    "# Remove the temporary file\n",
    "rm \"$(pwd)/TEMPP.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg \\\n",
    "-loop 1 -t 3 -i img001.jpg \\\n",
    "-loop 1 -t 3 -i img002.jpg \\\n",
    "-loop 1 -t 3 -i img003.jpg \\\n",
    "-loop 1 -t 3 -i img004.jpg \\\n",
    "-loop 1 -t 3 -i img005.jpg \\\n",
    "-filter_complex \\\n",
    "\"[0][1]xfade=transition=circlecrop:duration=0.5:offset=2.5[f0]; \\\n",
    "[f0][2]xfade=transition=smoothleft:duration=0.5:offset=5[f1]; \\\n",
    "[f1][3]xfade=transition=pixelize:duration=0.5:offset=7.5[f2]; \\\n",
    "[f2][4]xfade=transition=hblur:duration=0.5:offset=10[f3]\" \\\n",
    "-map \"[f3]\" -r 25 -pix_fmt yuv420p -vcodec libx264 output-swipe-custom.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "#from moviepy.video import transitions\n",
    "from moviepy.video.compositing import transitions\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "\n",
    "def zoom_inn(clip, duration):\n",
    "    \"\"\"Zooms in on a clip over a given duration\"\"\"\n",
    "    zoomed_clips = []\n",
    "    zoom_factor = 1.5 # Increase this value to zoom in more\n",
    "    for i in range(2):\n",
    "        zoomed_clips.append(clip.zoom(zoom_factor ** i))\n",
    "    transition = CompositeVideoClip([zoomed_clips[0], zoomed_clips[1].set_start(duration)], size=clip.size)\n",
    "    return transition.set_duration(duration)\n",
    "\n",
    "def zoom_in(clip, duration):\n",
    "    w, h = clip.size\n",
    "    zoom_factor = 1.5\n",
    "    zoomed_in = clip.zoom(zoom_factor)\n",
    "    zoomed_in = zoomed_in.set_position(('center', 'center'))\n",
    "    zoomed_in = zoomed_in.set_duration(duration)\n",
    "    return zoomed_in.margin(-w/2, -h/2, -w/2, -h/2)\n",
    "\n",
    "\n",
    "def zoom_out(clip, duration):\n",
    "    w, h = clip.size\n",
    "    zoom_factor = 1.5\n",
    "    zoomed_out = clip.zoom(zoom_factor)\n",
    "    zoomed_out = zoomed_out.set_position(('center', 'center'))\n",
    "    zoomed_out = zoomed_out.set_duration(duration)\n",
    "    return zoomed_out\n",
    "\n",
    "\n",
    "def get_random_transition():\n",
    "    transition_list = [\n",
    "        transitions.crossfadein,\n",
    "        transitions.crossfadeout,\n",
    "        transitions.slide_in(random.choice([\"left\", \"right\", \"top\", \"bottom\"])),\n",
    "        lambda: transitions.slide_out(random.choice([\"left\", \"right\", \"top\", \"bottom\"]))\n",
    "  \n",
    "    ]\n",
    "    return random.choice(transition_list)\n",
    "\n",
    "\n",
    "# Set the path to the directory containing the input images\n",
    "image_dir = '/home/jack/Desktop/HDD500/to-vid/building'\n",
    "\n",
    "# Set the output video parameters\n",
    "duration = 1 # Duration of each image in seconds\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "# Define a function to choose a random transition\n",
    "\n",
    "# Define a function to create a video clip from an image with a random transition\n",
    "def create_clip(filename):\n",
    "    transition = get_random_transition()\n",
    "    image_clip = ImageClip(filename).set_duration(duration)\n",
    "    return image_clip.fx(transition, duration=duration)\n",
    "\n",
    "# Create a list of video clips for each image with a random transition\n",
    "clips = [create_clip(filename) for filename in image_files]\n",
    "\n",
    "# Concatenate the video clips to create the final slideshow\n",
    "slideshow = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters and write the video file\n",
    "slideshow = slideshow.resize(size).set_fps(fps)\n",
    "slideshow.write_videofile(image_dir+'/slideshow.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.compositing import transitions\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "\n",
    "def zoom_inn(clip, duration):\n",
    "    \"\"\"Zooms in on a clip over a given duration\"\"\"\n",
    "    zoomed_clips = []\n",
    "    zoom_factor = 1.5 # Increase this value to zoom in more\n",
    "    for i in range(2):\n",
    "        zoomed_clips.append(clip.zoom(zoom_factor ** i))\n",
    "    transition = CompositeVideoClip([zoomed_clips[0], zoomed_clips[1].set_start(duration)], size=clip.size)\n",
    "    return transition.set_duration(duration)\n",
    "\n",
    "def zoom_in(clip, duration):\n",
    "    w, h = clip.size\n",
    "    zoom_factor = 1.5\n",
    "    zoomed_in = clip.zoom(zoom_factor)\n",
    "    zoomed_in = zoomed_in.set_position(('center', 'center'))\n",
    "    zoomed_in = zoomed_in.set_duration(duration)\n",
    "    return zoomed_in.margin(-w/2, -h/2, -w/2, -h/2)\n",
    "\n",
    "\n",
    "def zoom_out(clip, duration):\n",
    "    w, h = clip.size\n",
    "    zoom_factor = 1.5\n",
    "    zoomed_out = clip.zoom(zoom_factor)\n",
    "    zoomed_out = zoomed_out.set_position(('center', 'center'))\n",
    "    zoomed_out = zoomed_out.set_duration(duration)\n",
    "    return zoomed_out\n",
    "\n",
    "\n",
    "def slide_out_random_direction():\n",
    "    return transitions.slide_out(random.choice([\"left\", \"right\", \"top\", \"bottom\"]))\n",
    "\n",
    "def get_random_transition():\n",
    "    transition_list = [\n",
    "        transitions.crossfadein,\n",
    "        transitions.crossfadeout,\n",
    "        lambda: transitions.slide_in(random.choice([\"left\", \"right\", \"top\", \"bottom\"]), duration=duration),\n",
    "        lambda: transitions.slide_out(random.choice([\"left\", \"right\", \"top\", \"bottom\"]), duration=duration)\n",
    "    ]\n",
    "    return random.choice(transition_list)\n",
    "\n",
    "\n",
    "\n",
    "# Set the path to the directory containing the input images\n",
    "image_dir = '/home/jack/Desktop/HDD500/to-vid/building'\n",
    "\n",
    "# Set the output video parameters\n",
    "duration = 1 # Duration of each image in seconds\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "# Define a function to create a video clip from an image with a random transition\n",
    "def create_clip(filename):\n",
    "    transition = get_random_transition()\n",
    "    image_clip = ImageClip(filename).set_duration(duration)\n",
    "    return image_clip.fl_image(lambda img: transition(img, duration=duration))\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of video clips for each image with a random transition\n",
    "clips = [create_clip(filename) for filename in image_files]\n",
    "\n",
    "# Concatenate the video clips to create the final slideshow\n",
    "slideshow = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters and write the video file\n",
    "slideshow = slideshow.resize(size).set_fps(fps)\n",
    "slideshow.write_videofile(os.path.join(image_dir, 'slideshow.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f223d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.compositing import transitions\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "\n",
    "def zoom_inn(clip, duration):\n",
    "    \"\"\"Zooms in on a clip over a given duration\"\"\"\n",
    "    zoomed_clips = []\n",
    "    zoom_factor = 1.5 # Increase this value to zoom in more\n",
    "    for i in range(2):\n",
    "        zoomed_clips.append(clip.zoom(zoom_factor ** i))\n",
    "    transition = CompositeVideoClip([zoomed_clips[0], zoomed_clips[1].set_start(duration)], size=clip.size)\n",
    "    return transition.set_duration(duration)\n",
    "\n",
    "def zoom_in(clip, duration):\n",
    "    w, h = clip.size\n",
    "    zoom_factor = 1.5\n",
    "    zoomed_in = clip.zoom(zoom_factor)\n",
    "    zoomed_in = zoomed_in.set_position(('center', 'center'))\n",
    "    zoomed_in = zoomed_in.set_duration(duration)\n",
    "    return zoomed_in.margin(-w/2, -h/2, -w/2, -h/2)\n",
    "\n",
    "\n",
    "def zoom_out(clip, duration):\n",
    "    w, h = clip.size\n",
    "    zoom_factor = 1.5\n",
    "    zoomed_out = clip.zoom(zoom_factor)\n",
    "    zoomed_out = zoomed_out.set_position(('center', 'center'))\n",
    "    zoomed_out = zoomed_out.set_duration(duration)\n",
    "    return zoomed_out\n",
    "\n",
    "\n",
    "def slide_out_random_direction():\n",
    "    return transitions.slide_out(random.choice([\"left\", \"right\", \"top\", \"bottom\"]))\n",
    "\n",
    "\"\"\"def get_random_transition():\n",
    "    transition_list = [\n",
    "        transitions.crossfadein,\n",
    "        transitions.crossfadeout,\n",
    "        lambda: transitions.slide_in(random.choice([\"left\", \"right\", \"top\", \"bottom\"]), duration=duration),\n",
    "        lambda: transitions.slide_out(random.choice([\"left\", \"right\", \"top\", \"bottom\"]), duration=duration)\n",
    "    ]\n",
    "    return random.choice(transition_list)\n",
    "\"\"\"\n",
    "def get_random_transition():\n",
    "    transition_list = [\n",
    "        zoom_inn,\n",
    "        zoom_in,\n",
    "        zoom_out\n",
    "    ]\n",
    "    return random.choice(transition_list)\n",
    "\n",
    "\n",
    "\n",
    "# Set the path to the directory containing the input images\n",
    "image_dir = '/home/jack/Desktop/HDD500/to-vid/building'\n",
    "\n",
    "# Set the output video parameters\n",
    "duration = 1 # Duration of each image in seconds\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "# Define a function to create a video clip from an image with a random transition\n",
    "def create_clips(filename):\n",
    "    transition = get_random_transition()\n",
    "    image_clip = ImageClip(filename).set_duration(duration)\n",
    "    return image_clip.fl_image(lambda img: transition(img, duration=duration))\n",
    "def create_clip(filename):\n",
    "    transition = get_random_transition()\n",
    "    image_clip = VideoFileClip(filename, audio=False).set_duration(duration)\n",
    "    return image_clip.fl_image(lambda img: transition(img, duration=duration))\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of video clips for each image with a random transition\n",
    "clips = [create_clip(filename) for filename in image_files]\n",
    "\n",
    "# Concatenate the video clips to create the final slideshow\n",
    "slideshow = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters and write the video file\n",
    "slideshow = slideshow.resize(size).set_fps(fps)\n",
    "slideshow.write_videofile(os.path.join(image_dir, 'slideshow.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a585ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import *\n",
    "import random\n",
    "import glob\n",
    "# Set the output video parameters\n",
    "duration = .5 # Duration of each image in seconds\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_dir = '/home/jack/Desktop/HDD500/to-vid/building/'\n",
    "image_files = random.sample(glob.glob(image_dir+'*.jpg'), 30)\n",
    "\n",
    "# Define the crossfade transition\n",
    "crossfade = lambda clip1, clip2: CompositeVideoClip([clip1, clip2.set_start(clip1.duration - duration)], size=size)\n",
    "\n",
    "# Create a list of image clips with crossfades\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a crossfade transition to the previous clip\n",
    "        transition = crossfade(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshow1.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.compositing import *\n",
    "# Set the output video parameters\n",
    "\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_dir = '/home/jack/Desktop/HDD500/to-vid/building/*.jpg'\n",
    "image_files = random.sample(glob.glob(image_dir), 40)\n",
    "# Define the transitions\n",
    "duration = 1 # Duration of each image in seconds\n",
    "transitions = [transitions.crossfadein, transitions.crossfadeout]\n",
    "random_transition = lambda clip1, clip2: random.choice(transitions)(clip1, clip2)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(os.path.join(image_files[i])).set_duration(1)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a random transition to the previous clip\n",
    "        transition = random_transition(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshow2.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "dir(moviepy.video.compositing.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30227800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),20)\n",
    "\n",
    "# Define the transitions\n",
    "def crossfade(clip1, clip2):\n",
    "    return CompositeVideoClip([clip1, clip2.set_start(clip1.duration - duration)], size=size)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a crossfade transition to the previous clip\n",
    "        transition = crossfade(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshow.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceec581",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/jack/Desktop/HDD500/to-vid/building/01145.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dec891",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (image_files[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a1f678",
   "metadata": {},
   "source": [
    "# Good working with fade transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.fx import *\n",
    "dir(vfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good working with fade transition\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),30)\n",
    "\n",
    "# Define the transitions\n",
    "def crossfade(clip1, clip2):\n",
    "    return CompositeVideoClip([clip1.fx(vfx.fadeout, duration=1), \n",
    "                               clip2.fx(vfx.fadein, duration=1)], \n",
    "                              size=size)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a crossfade transition to the previous clip\n",
    "        transition = crossfade(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshowT.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5147ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),30)\n",
    "\n",
    "# Define the transitions\n",
    "def wipe(clip1, clip2, transition_type=\"right\"):\n",
    "    if transition_type == \"right\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_x)\n",
    "        mask = mask.crop(x1=0, y1=0, x2=mask.w*(clip2.start/clip2.duration), y2=mask.h)\n",
    "        mask = mask.set_position((\"left\",\"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"right\",\"top\")).fx(vfx.mask_color, color=(0,0,0), mask=mask)])\n",
    "    elif transition_type == \"left\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_x)\n",
    "        mask = mask.crop(x1=mask.w*(1-clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"right\",\"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"left\",\"top\")).fx(vfx.mask_color, color=(0,0,0), mask=mask)])\n",
    "    elif transition_type == \"bottom\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_y)\n",
    "        mask = mask.crop(x1=0, y1=0, x2=mask.w, y2=mask.h*(clip2.start/clip2.duration))\n",
    "        mask = mask.set_position((\"center\",\"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"center\",\"bottom\")).fx(vfx.mask_color, color=(0,0,0), mask=mask)])\n",
    "    elif transition_type == \"top\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_y)\n",
    "        mask = mask.crop(x1=0, y1=mask.h*(1-clip2.start/clip2.duration), x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"center\",\"bottom\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"center\",\"top\")).fx(vfx.mask_color, color=(0,0,0), mask=mask)])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transition type\")\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a wipe transition to the previous clip\n",
    "        transition = wipe(clips[-1], image_clip, \"left\")\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Apply a wipe transition\n",
    "video = video.fx(vfx.wipe, horizontal=True, duration=1)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshoww.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),30)\n",
    "\n",
    "# Define the wipe transition\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    # Create a mask clip for the transition\n",
    "    mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "    if transition_type == \"right\":\n",
    "        mask = mask.crop(x1=0, y1=0, x2=mask.w*clip2.start/clip2.duration, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\",\"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"right\",\"top\")).mask_video(mask)])\n",
    "    elif transition_type == \"left\":\n",
    "        mask = mask.crop(x1=mask.w*(1-clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"right\",\"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"right\",\"top\")), clip2.set_position((\"left\",\"top\")).mask_video(mask)])\n",
    "    elif transition_type == \"bottom\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_y)\n",
    "        mask = mask.crop(x1=0, y1=0, x2=mask.w, y2=mask.h*clip2.start/clip2.duration)\n",
    "        mask = mask.set_position((\"center\",\"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"center\",\"bottom\")).mask_video(mask)])\n",
    "    elif transition_type == \"top\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration)\n",
    "        mask = mask.crop(x1=0, y1=mask.h*(1-clip2.start/clip2.duration), x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"center\",\"bottom\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"center\",\"top\")).mask_video(mask)])\n",
    "    else:\n",
    "        return clip2\n",
    "\n",
    "# Create a list of image clips with wipe transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a wipe transition to the previous clip\n",
    "        transition = wipe(clips[-1], image_clip, \"right\")\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/HDD500/to-vid/building/slideshowW.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import all as vfx\n",
    "\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    size = clip1.size\n",
    "    duration = clip1.duration\n",
    "    mask = ColorClip(size, color=(0,0,0), duration=duration)\n",
    "    if transition_type == \"right\":\n",
    "        mask = mask.crop(x1=0, y1=0, x2=mask.w*clip2.start/clip2.duration, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\",\"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"right\",\"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"left\":\n",
    "        mask = mask.crop(x1=mask.w*(1-clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\",\"top\"))\n",
    "        return CompositeVideoClip([clip1.set_mask(mask), clip2.set_position((\"left\",\"top\"))])\n",
    "    elif transition_type == \"top\":\n",
    "        mask = mask.crop(x1=0, y1=mask.h*(1-clip2.start/clip2.duration), x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"top\",\"left\"))\n",
    "        return CompositeVideoClip([clip1.set_mask(mask), clip2.set_position((\"left\",\"top\"))])\n",
    "    elif transition_type == \"bottom\":\n",
    "        mask = mask.crop(x1=0, y1=0, x2=mask.w, y2=mask.h*clip2.start/clip2.duration)\n",
    "        mask = mask.set_position((\"bottom\",\"left\"))\n",
    "        return CompositeVideoClip([clip1.set_mask(mask), clip2.set_position((\"left\",\"top\"))])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transition type\")\n",
    "\n",
    "def slideshow(image_files, duration, transition_type=\"right\"):\n",
    "    clips = []\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image_clip = ImageClip(image_file).set_duration(duration)\n",
    "        if i == 0:\n",
    "            clips.append(image_clip)\n",
    "        else:\n",
    "            transition = wipe(clips[-1], image_clip, transition_type)\n",
    "            clips.append(transition)\n",
    "        clips.append(image_clip)\n",
    "    return concatenate_videoclips(clips)\n",
    "\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'),30)\n",
    "duration = 5\n",
    "transition_type = \"left\"\n",
    "slideshow = slideshow(image_files, duration, transition_type)\n",
    "slideshow.write_videofile(\"slideshowx.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.VideoClip import ColorClip\n",
    "from moviepy.video.VideoClip import ImageClip\n",
    "from moviepy.video import fx as vfx\n",
    "from PIL import Image\n",
    "import random\n",
    "import glob\n",
    "\n",
    "\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    size = clip1.size\n",
    "    duration = clip1.duration\n",
    "    image_clip = ImageClip(Image.new(\"RGB\", size, \"black\"), duration=duration)\n",
    "    if transition_type == \"right\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\", \"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"right\", \"top\")), clip2.set_position((\"left\", \"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"left\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(1-clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"right\", \"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"left\", \"top\")), clip2.set_position((\"right\", \"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"bottom\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_y)\n",
    "        mask = mask.crop(x1=0, y1=mask.h*(clip2.start/clip2.duration), x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"bottom\",\"center\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"top\",\"center\")), clip2.set_position((\"bottom\",\"center\")).set_mask(mask)])\n",
    "\n",
    "\n",
    "def slideshow(images_path, duration=1, transition_type=\"right\"):\n",
    "    clips = []\n",
    "    for path in images_path:\n",
    "        clip = VideoFileClip(path, audio=False).resize(height=720)\n",
    "        print(f\"Loaded image from {path}\")\n",
    "        clips.append(clip)\n",
    "    for i in range(1, len(clips)):\n",
    "        transition = wipe(clips[i-1], clips[i], transition_type)\n",
    "        clips.append(transition)\n",
    "    final_clip = CompositeVideoClip(clips, duration=duration*len(images_path))\n",
    "    return final_clip\n",
    "\n",
    "image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/to-vid/building/*.jpg'), 30)\n",
    "duration = 5\n",
    "transition_type = \"left\"\n",
    "slideshow = slideshow(image_files, duration, transition_type)\n",
    "slideshow.write_videofile(\"slideshowx.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.VideoClip import ColorClip\n",
    "from moviepy.video.VideoClip import ImageClip\n",
    "from moviepy.video import fx as vfx\n",
    "\n",
    "\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    size = clip1.size\n",
    "    duration = clip1.duration\n",
    "    image_clip = ImageClip(Image.new(\"RGB\", size, \"black\"), duration=duration)\n",
    "    if transition_type == \"right\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\", \"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"right\", \"top\")), clip2.set_position((\"left\", \"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"left\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(1-clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"right\", \"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"left\", \"top\")), clip2.set_position((\"right\", \"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"bottom\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_y)\n",
    "        mask = mask.crop(x1=0, y1=mask.h*(clip2.start/clip2.duration), x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"bottom\",\"center\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"top\",\"center\")), clip2.set_position((\"bottom\",\"center\")).set_mask(mask)])\n",
    "\n",
    "\n",
    "def slideshow(images_path, duration=1, transition_type=\"right\"):\n",
    "    clips = []\n",
    "    for path in images_path:\n",
    "        with Image.open(path) as img:\n",
    "            clip = ImageClip(img).resize(height=720)\n",
    "        print(f\"Loaded image from {path}\")\n",
    "        clips.append(clip)\n",
    "    for i in range(1, len(clips)):\n",
    "        transition = wipe(clips[i-1], clips[i], transition_type)\n",
    "        clips.append(transition)\n",
    "    final_clip = CompositeVideoClip(clips, duration=duration*len(images_path))\n",
    "    return final_clip\n",
    "\n",
    "\n",
    "image_folder = '/home/jack/Desktop/HDD500/to-vid/building'\n",
    "image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "image_files = random.sample(image_files, 30)\n",
    "\n",
    "duration = 5\n",
    "transition_type = \"left\"\n",
    "slideshow = slideshow(image_files, duration, transition_type)\n",
    "slideshow.write_videofile(\"slideshow.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceba0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "from moviepy.editor import VideoClip, VideoFileClip, clips_array\n",
    "\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    if transition_type == \"right\":\n",
    "        return clips_array([[clip1.crossfadein(1), clip2.crossfadein(1).margin(10)]])\n",
    "    elif transition_type == \"left\":\n",
    "        return clips_array([[clip1.crossfadein(1).margin(10), clip2.crossfadein(1)]])\n",
    "    elif transition_type == \"bottom\":\n",
    "        return clips_array([[clip1.crossfadein(1).margin(10)], [clip2.crossfadein(1)]])\n",
    "\n",
    "def slideshow(images_path, duration=1, transition_type=\"right\"):\n",
    "    clips = []\n",
    "    for path in images_path:\n",
    "        img_clip = VideoFileClip(path).resize(height=720)\n",
    "        print(f\"Loaded image from {path}\")\n",
    "        clips.append(img_clip)\n",
    "    for i in range(1, len(clips)):\n",
    "        transition = wipe(clips[i-1], clips[i], transition_type)\n",
    "        clips.append(transition)\n",
    "    final_clip = clips_array(clips, duration=duration*len(images_path))\n",
    "    return final_clip\n",
    "\n",
    "image_folder = 'static/images'\n",
    "image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "image_files = random.sample(image_files, 5)\n",
    "\n",
    "duration = 5\n",
    "transition_type = \"left\"\n",
    "slideshow_clip = slideshow(image_files, duration, transition_type)\n",
    "slideshow_clip.write_videofile(\"steamslideshow.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10231715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.VideoClip import ColorClip\n",
    "from moviepy.video.VideoClip import ImageClip\n",
    "from moviepy.video import fx as vfx\n",
    "import numpy as np\n",
    "\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    size = clip1(0).shape[:2][::-1]\n",
    "    duration = clip1.duration\n",
    "    image_clip = ImageClip(np.zeros((size[1], size[0], 3), dtype=np.uint8), duration=duration)\n",
    "    if transition_type == \"right\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\", \"top\"))\n",
    "        return CompositeVideoClip([clip1, clip2.set_position((\"left\", \"top\")).set_mask(mask)])\n",
    "    # Similar for other transition types...\n",
    "\n",
    "def slideshow(images_path, duration=1, transition_type=\"right\"):\n",
    "    clips = []\n",
    "    for path in images_path:\n",
    "        img = cv2.imread(path)\n",
    "        clips.append(lambda t: img)\n",
    "        print(f\"Loaded image from {path}\")\n",
    "    for i in range(1, len(clips)):\n",
    "        transition = wipe(clips[i-1], clips[i], transition_type)\n",
    "        clips.append(transition)\n",
    "    final_clip = CompositeVideoClip(clips, duration=duration*len(images_path))\n",
    "    return final_clip\n",
    "\n",
    "image_folder = '/home/jack/Desktop/StoryMaker/static/images/steampunk/personal-feed_files'\n",
    "image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "image_files = random.sample(image_files, 30)\n",
    "\n",
    "duration = 5\n",
    "transition_type = \"left\"\n",
    "slideshow = slideshow(image_files, duration, transition_type)\n",
    "slideshow.write_videofile(\"steamslideshow.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cef2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.VideoClip import ColorClip\n",
    "from moviepy.video.VideoClip import ImageClip\n",
    "from moviepy.video import fx as vfx\n",
    "\n",
    "\n",
    "def wipe(clip1, clip2, transition_type):\n",
    "    size = clip1.size\n",
    "    duration = clip1.duration\n",
    "    image_clip = ImageClip(Image.new(\"RGB\", size, \"black\"), duration=duration)\n",
    "    if transition_type == \"right\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"left\", \"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"right\", \"top\")), clip2.set_position((\"left\", \"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"left\":\n",
    "        mask = ColorClip(size, color=(255, 255, 255), duration=duration)\n",
    "        mask = mask.crop(x1=mask.w*(1-clip2.start/clip2.duration), y1=0, x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"right\", \"top\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"left\", \"top\")), clip2.set_position((\"right\", \"top\")).set_mask(mask)])\n",
    "    elif transition_type == \"bottom\":\n",
    "        mask = ColorClip(size, color=(0,0,0), duration=duration).fx(vfx.mirror_y)\n",
    "        mask = mask.crop(x1=0, y1=mask.h*(clip2.start/clip2.duration), x2=mask.w, y2=mask.h)\n",
    "        mask = mask.set_position((\"bottom\",\"center\"))\n",
    "        return CompositeVideoClip([clip1.set_position((\"top\",\"center\")), clip2.set_position((\"bottom\",\"center\")).set_mask(mask)])\n",
    "\n",
    "def slideshow(images_path, duration=1, transition_type=\"right\"):\n",
    "    clips = []\n",
    "    for path in images_path:\n",
    "        img = cv2.imread(path)\n",
    "        clips.append(lambda t: img)  # Create a frame generator function\n",
    "        print(f\"Loaded image from {path}\")\n",
    "    for i in range(1, len(clips)):\n",
    "        transition = wipe(clips[i-1], clips[i], transition_type)\n",
    "        clips.append(transition)\n",
    "    final_clip = CompositeVideoClip(clips, duration=duration*len(images_path))\n",
    "    return final_clip\n",
    "\n",
    "\n",
    "image_folder = '/home/jack/Desktop/StoryMaker/static/images/steampunk/personal-feed_files'\n",
    "image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "image_files = random.sample(image_files, 30)\n",
    "\n",
    "duration = 5\n",
    "transition_type = \"left\"\n",
    "slideshow = slideshow(image_files, duration, transition_type)\n",
    "slideshow.write_videofile(\"steamslideshow.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e15069",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamslideshow.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from moviepy.video.VideoClip import ImageClip, ColorClip\n",
    "from moviepy.video.compositing.concatenate import concatenate_videoclips\n",
    "\n",
    "def slideshow(images_path, duration, transition_type):\n",
    "    clips = []\n",
    "    transition_duration = 1\n",
    "    \n",
    "    if transition_type == \"fade\":\n",
    "        transition_clip = ColorClip((1280, 720), color=(0, 0, 0), duration=transition_duration)\n",
    "        transition_clip = transition_clip.crossfadein(transition_duration)\n",
    "    \n",
    "    for path in images_path:\n",
    "        with Image.open(path) as img:\n",
    "            clip = ImageClip(img).resize(height=720)\n",
    "        print(f\"Loaded image from {path}\")\n",
    "        clips.append(clip)\n",
    "        if transition_type == \"fade\":\n",
    "            clips.append(transition_clip)\n",
    "\n",
    "    final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_clip = final_clip.set_duration(duration)\n",
    "    return final_clip\n",
    "\n",
    "# Example usage\n",
    "image_folder = '/home/jack/Desktop/HDD500/to-vid/building'\n",
    "image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "image_files = random.sample(image_files, 30)\n",
    "duration = 10  # in seconds\n",
    "transition_type = \"fade\"\n",
    "slideshow_clip = slideshow(image_files, duration, transition_type)\n",
    "slideshow_clip.write_videofile(\"slideshow.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx.all import painting\n",
    "import subprocess\n",
    "\n",
    "# Load the video clip\n",
    "clip = VideoFileClip(\"/home/jack/Desktop/HDD500/collections/newdownloads/mine-new/newvid/JOINED01.mp4\")\n",
    "\n",
    "# Apply the painting effect\n",
    "painted_clip = clip.fx(painting, saturation=1.4, black=0.006)\n",
    "\n",
    "# Write the painted clip to a new file\n",
    "painted_clip.write_videofile(\"/home/jack/Desktop/HDD500/collections/newdownloads/mine-new/newvid/JOINED_painting.mp4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames=$(ffprobe -v error -select_streams v:0 -count_packets -show_entries stream=nb_read_packets -of csv=p=0 /home/jack/Desktop/HDD500/collections/newdownloads/mine-new/newvid/JOINED01.mp4)\n",
    "echo $num_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of frames in the painted clip using ffmpeg\n",
    "command = [\"ffmpeg\", \"-i\", \"/home/jack/Desktop/HDD500/collections/newdownloads/mine-new/newvid/JOINED01.mp4\", \"-v\", \"error\", \"-count_frames\", \"-select_streams\", \"v:0\", \"-show_entries\", \"stream=nb_frames\", \"-of\", \"default=nokey=1:noprint_wrappers=1\"]\n",
    "num_frames = int(subprocess.check_output(command))\n",
    "\n",
    "print(f\"The painted video has {num_frames} frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good working with fade transition\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "#image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/collections/newdownloads/512x512/*.jpg'),30)\n",
    "\n",
    "image_files = sorted(glob.glob('/home/jack/Desktop/monitor_project/*.jpg'))\n",
    "\n",
    "# Define the transitions\n",
    "def crossfade(clip1, clip2):\n",
    "    return CompositeVideoClip([clip1.fx(vfx.fadeout, duration=.25), \n",
    "                               clip2.fx(vfx.fadein, duration=.25)], \n",
    "                              size=size)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a crossfade transition to the previous clip\n",
    "        transition = crossfade(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/monitor_project/slideshowNEW2-5.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870875f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "from moviepy.video.compositing.transitions import WipeTransition\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "#image_files = random.sample(glob.glob('/home/jack/Desktop/HDD500/collections/newdownloads/512x512/*.jpg'),30)\n",
    "\n",
    "image_files = sorted(glob.glob('/home/jack/Desktop/monitor_project/*.jpg'))\n",
    "\n",
    "# Define the transitions\n",
    "def crossfade(clip1, clip2):\n",
    "    return CompositeVideoClip([clip1.fx(vfx.fadeout, duration=1), \n",
    "                               clip2.fx(vfx.fadein, duration=1)], \n",
    "                              size=size)\n",
    "\n",
    "def vertical_wipe(clip1, clip2):\n",
    "    return WipeTransition(clip1, clip2, direction='vertical', duration=1)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a wipe transition to the previous clip\n",
    "        transition = vertical_wipe(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/monitor_project/slideshowNEW2.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915788fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.fx import *\n",
    "import glob\n",
    "\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (640, 640) # Size of the output video\n",
    "duration = 1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = sorted(glob.glob('/home/jack/Desktop/monitor_project/*.jpg'))\n",
    "\n",
    "# Define the wipe transition\n",
    "def vertical_wipe(clip1, clip2):\n",
    "    return wipe(clip1, clip2, transition='vertical', duration=1)\n",
    "\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a vertical wipe transition to the previous clip\n",
    "        transition = vertical_wipe(clips[-1], image_clip)\n",
    "        clips.append(transition)\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('/home/jack/Desktop/monitor_project/slideshowNEW2.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c99a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.video.compositing.transitions\n",
    "dir(moviepy.video.compositing.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a094b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.compositing.transitions import slide_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jack/Desktop/StoryMaker/steampunk/*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650fa7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video steampunk/slideshowSharp.mp4.\n",
      "Moviepy - Writing video steampunk/slideshowSharp.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready steampunk/slideshowSharp.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.compositing.transitions import slide_in\n",
    "from moviepy.video.fx import all\n",
    "from moviepy.editor import *\n",
    "import glob\n",
    "import random\n",
    "# Set the output video parameters\n",
    "fps = 25 # Frames per second\n",
    "size = (768, 512) # Size of the output video\n",
    "duration =1 # Duration of each image in seconds\n",
    "\n",
    "# Get a list of the image filenames in the directory\n",
    "image_files = sorted(glob.glob('/home/jack/Desktop/StoryMaker/static/images/steampunk/NewFolder/*.jpg'))\n",
    "#print(image_files)\n",
    "# Create a list of image clips with transitions\n",
    "clips = []\n",
    "\n",
    "for i in range(len(image_files)):\n",
    "    # Load the image and create a video clip\n",
    "    image_clip = ImageClip(image_files[i]).set_duration(duration)\n",
    "    direction = random.choice(['right','left','top','bottom'])\n",
    "    \n",
    "    if i > 0:\n",
    "        # Add a vertical slide transition to the previous clip\n",
    "        transition = slide_in(image_clip, duration=1, side=direction)\n",
    "        clips.append(CompositeVideoClip([clips[-1], transition]).set_duration(1))\n",
    "        \n",
    "    clips.append(image_clip)\n",
    "\n",
    "# Concatenate the clips to create the final video\n",
    "video = concatenate_videoclips(clips)\n",
    "\n",
    "# Set the output video parameters\n",
    "video = video.set_fps(fps)\n",
    "video = video.resize(size)\n",
    "\n",
    "# Save the video\n",
    "video.write_videofile('steampunk/slideshowSharp.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4ad34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73873bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m000000000061c1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6494001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6494001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6494001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007f64a8c15060\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f64a8c19080] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007f64a8c15060\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f649475eb30\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f649475eb30\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f649475eb30\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f64a8c9ad40] \u001b[0m\u001b[1;31mget_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c9ad40] \u001b[0m\u001b[1;31mthread_get_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c9ad40] \u001b[0m\u001b[1;31mdecode_slice_header error\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c9ad40] \u001b[0m\u001b[1;31mno frame!\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c19080] \u001b[0m\u001b[1;31mget_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c19080] \u001b[0m\u001b[1;31mthread_get_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c19080] \u001b[0m\u001b[1;31mdecode_slice_header error\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f64a8c19080] \u001b[0m\u001b[1;31mno frame!\n",
      "\u001b[0mQObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc steampunk/slideshowSharp.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a287112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import concatenate_videoclips\n",
    "from moviepy.video.compositing.transitions import (\n",
    "    CrossfadeIn, CrossfadeOut, SlideIn, SlideOut, ZoomIn, ZoomOut, WarpIn, WarpOut\n",
    ")\n",
    "\n",
    "# Create instances of the transition classes\n",
    "transition1 = CrossfadeIn()\n",
    "transition2 = CrossfadeOut()\n",
    "transition3 = SlideIn()\n",
    "transition4 = SlideOut()\n",
    "transition5 = ZoomIn()\n",
    "transition6 = ZoomOut()\n",
    "transition7 = WarpIn()\n",
    "transition8 = WarpOut()\n",
    "\n",
    "# Concatenate video clips with transitions\n",
    "video_clips = [clip1, clip2, clip3]  # Replace with your actual video clips\n",
    "transitions = [transition1, transition2, transition3, transition4, transition5, transition6, transition7, transition8]\n",
    "final_clip = concatenate_videoclips(video_clips, transitions=transitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Requires scikit-image installed (for ``vfx.painting``).\"\"\"\n",
    "\n",
    "from moviepy import *\n",
    "\n",
    "\n",
    "# WE TAKE THE SUBCLIPS WHICH ARE 2 SECONDS BEFORE & AFTER THE FREEZE\n",
    "\n",
    "charade = VideoFileClip(\"../../videos/charade.mp4\")\n",
    "tfreeze = convert_to_seconds(19.21)  # Time of the freeze, 19'21\n",
    "\n",
    "clip_before = charade.subclip(tfreeze - 2, tfreeze)\n",
    "clip_after = charade.subclip(tfreeze, tfreeze + 2)\n",
    "\n",
    "\n",
    "# THE FRAME TO FREEZE\n",
    "\n",
    "im_freeze = charade.to_ImageClip(tfreeze)\n",
    "painting = charade.fx(vfx.painting, saturation=1.6, black=0.006).to_ImageClip(tfreeze)\n",
    "\n",
    "txt = TextClip(\"Audrey\", font=\"Amiri-regular\", font_size=35)\n",
    "\n",
    "painting_txt = (\n",
    "    CompositeVideoClip([painting, txt.set_pos((10, 180))])\n",
    "    .add_mask()\n",
    "    .with_duration(3)\n",
    "    .crossfadein(0.5)\n",
    "    .crossfadeout(0.5)\n",
    ")\n",
    "\n",
    "# FADEIN/FADEOUT EFFECT ON THE PAINTED IMAGE\n",
    "\n",
    "painting_fading = CompositeVideoClip([im_freeze, painting_txt])\n",
    "\n",
    "# FINAL CLIP AND RENDERING\n",
    "\n",
    "final_clip = concatenate_videoclips(\n",
    "    [clip_before, painting_fading.with_duration(3), clip_after]\n",
    ")\n",
    "\n",
    "final_clip.write_videofile(\n",
    "    \"../../audrey.avi\", fps=charade.fps, codec=\"mpeg4\", audio_bitrate=\"3000k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mohttp://localhost:8888/notebooks/Imports_moviepy-ffmpeg.ipynb#viepy.editor import concatenate_videoclips\n",
    "from moviepy.video.fx import fadein, fadeout, slide_in, slide_out, zoom_in, zoom_out, warp_in, warp_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.video\n",
    "dir (moviepy.video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c799cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video import fx,io,tools,VideoClip,compositing\n",
    "dir(compositing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3272774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video import fx,io,tools,VideoClip,compositing\n",
    "dir (compositing.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.compositing.transitions import crossfadeinout, crossfadeoutin, slide_in, slide_out, zoom_in, zoom_out, warp_in, warp_outfrom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f056e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video import fx,io,tools,VideoClip,compositing\n",
    "compositing.fadein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video import fx,io,tools,VideoClip,compositing\n",
    "dir (compositing.CompositeVideoClip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video import ImageClip, concatenate_videoclips\n",
    "from moviepy.video.compositing.transitions import crossfadeinout, crossfadeoutin, slide_in, slide_out, zoom_in, zoom_out, warp_in, warp_out\n",
    "import random\n",
    "\n",
    "def get_random_transition(duration):\n",
    "    transition_list = [\n",
    "        crossfadeinout,\n",
    "        crossfadeoutin,\n",
    "        slide_in,\n",
    "        lambda: slide_out(random.choice([\"left\", \"right\", \"top\", \"bottom\"])),\n",
    "        zoom_in,\n",
    "        zoom_out,\n",
    "        warp_in,\n",
    "        warp_out\n",
    "    ]\n",
    "    return random.choice(transition_list)(duration=duration)\n",
    "image_files= random.sample(glob.glob(\"/home/jack/Desktop/StoryMaker/static/current_project/Misc/portrait/*.jpg\"),10)\n",
    "#image_files = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpg\"]\n",
    "clips = []\n",
    "for filename in image_files:\n",
    "    clip = ImageClip(filename).set_duration(2)\n",
    "    transition = get_random_transition(1)\n",
    "    clips.append(clip.fx(transition))\n",
    "\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "final_clip.write_videofile(\"slideshow.mp4\", fps=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cccb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vlc slideshow.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b26ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/jack/Desktop/StoryMaker/newvid/text.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Requires scikit-image installed (for ``vfx.painting``).\"\"\"\n",
    "\n",
    "from moviepy import *\n",
    "\n",
    "\n",
    "# WE TAKE THE SUBCLIPS WHICH ARE 2 SECONDS BEFORE & AFTER THE FREEZE\n",
    "\n",
    "charade = VideoFileClip(\"/home/jack/Desktop/StoryMaker/newvid/text.mp4\")\n",
    "#tfreeze = convert_to_seconds(19.21)  # Time of the freeze, 19'21\n",
    "tfreeze = 3  # Time of the freeze, 19'21\n",
    "\n",
    "clip_before = charade.subclip(tfreeze - 2, tfreeze)\n",
    "clip_after = charade.subclip(tfreeze, tfreeze + 2)\n",
    "\n",
    "\n",
    "# THE FRAME TO FREEZE\n",
    "\n",
    "im_freeze = charade.to_ImageClip(tfreeze)\n",
    "painting = charade.fx(vfx.painting, saturation=1.6, black=0.006).to_ImageClip(tfreeze)\n",
    "\n",
    "txt = TextClip(\"Audrey\", font=\"Amiri-regular\", font_size=35)\n",
    "\n",
    "painting_txt = (\n",
    "    CompositeVideoClip([painting, txt.set_pos((10, 180))])\n",
    "    .add_mask()\n",
    "    .with_duration(3)\n",
    "    .crossfadein(0.5)\n",
    "    .crossfadeout(0.5)\n",
    ")\n",
    "\n",
    "# FADEIN/FADEOUT EFFECT ON THE PAINTED IMAGE\n",
    "\n",
    "painting_fading = CompositeVideoClip([im_freeze, painting_txt])\n",
    "\n",
    "# FINAL CLIP AND RENDERING\n",
    "\n",
    "final_clip = concatenate_videoclips(\n",
    "    [clip_before, painting_fading.with_duration(3), clip_after]\n",
    ")\n",
    "\n",
    "final_clip.write_videofile(\n",
    "    \"freeze.avi\", fps=charade.fps, codec=\"mpeg4\", audio_bitrate=\"3000k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc8ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloned-base",
   "language": "python",
   "name": "cloned-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
